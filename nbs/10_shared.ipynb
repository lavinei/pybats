{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp shared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shared Functions\n",
    "\n",
    "> This module contains various shared helper functions for examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#exporti\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sc\n",
    "import pickle\n",
    "from scipy.special import digamma\n",
    "from pandas.tseries.holiday import AbstractHolidayCalendar, USMartinLutherKingJr, USMemorialDay, Holiday, USLaborDay, \\\n",
    "    USThanksgivingDay\n",
    "import os\n",
    "import pickle\n",
    "import zlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "\n",
    "def load_interpolators():\n",
    "    \n",
    "    pkg_data_dir = os.path.dirname(os.path.abspath(__file__)) + '/pkg_data'\n",
    "    #pkg_data_dir = os.getcwd().split('pybats')[0] + 'pybats/pybats/pkg_data'\n",
    "    #pkg_data_dir = globals()['_dh'][0] + '/pkg_data'\n",
    "\n",
    "    try:\n",
    "        with open(pkg_data_dir + '/interp_beta.pickle.gzip', 'rb') as fl:\n",
    "            interp_beta = pickle.loads(zlib.decompress(fl.read()))\n",
    "\n",
    "        with open(pkg_data_dir + '/interp_gamma.pickle.gzip', 'rb') as fl:\n",
    "            interp_gamma = pickle.loads(zlib.decompress(fl.read()))\n",
    "\n",
    "    except:\n",
    "        print('WARNING: Unable to load interpolator. Code will run slower.')\n",
    "        interp_beta, interp_gamma = None, None\n",
    "        \n",
    "    return interp_beta, interp_gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "# I need this helper in a module file for pickle reasons ...\n",
    "def transformer(ft, qt, fn1, fn2):\n",
    "    return np.exp(np.ravel(fn1(ft, np.sqrt(qt), grid=False))), \\\n",
    "           np.exp(np.ravel(fn2(ft, np.sqrt(qt), grid=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "def gamma_transformer(ft, qt, fn):\n",
    "    alpha = np.ravel(np.exp(fn(np.sqrt(qt))))\n",
    "    beta = np.exp(digamma(alpha) - ft)\n",
    "    return alpha, beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "def trigamma(x):\n",
    "    return sc.special.polygamma(x=x, n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "def save(obj, filename):\n",
    "    with open(filename, \"wb\") as file:\n",
    "        pickle.dump(obj, file=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "def load(filename):\n",
    "    with open(filename, \"rb\") as file:\n",
    "        tmp = pickle.load(file)\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "def define_holiday_regressors(X, dates, holidays=None):\n",
    "    \"\"\"\n",
    "    Add columns to the predictor matrix X for a specified list of holidays\n",
    "\n",
    "    :param X: (Array) Predictor matrix without columns for the holidays\n",
    "    :param dates: Dates\n",
    "    :param holidays: (List) holidays\n",
    "    :return: Updated predictor matrix\n",
    "    \"\"\"\n",
    "    if holidays is not None:\n",
    "        if len(holidays) > 0:\n",
    "            if X is None:\n",
    "                n = len(dates)\n",
    "            else:\n",
    "                n = X.shape[0]\n",
    "\n",
    "            for holiday in holidays:\n",
    "                cal = AbstractHolidayCalendar()\n",
    "                cal.rules = [holiday]\n",
    "                x = np.zeros(n)\n",
    "                x[dates.isin(cal.holidays())] = 1\n",
    "                if X is None:\n",
    "                    X = x\n",
    "                else:\n",
    "                    X = np.c_[X, x]\n",
    "\n",
    "            return X\n",
    "        else:\n",
    "            return X\n",
    "    else:\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def load_standard_holidays():\n",
    "    \"\"\"\n",
    "    Load in a list of standard holidays\n",
    "    \"\"\"\n",
    "    \n",
    "    holidays = [USMartinLutherKingJr,\n",
    "                USMemorialDay,\n",
    "                Holiday('July4', month=7, day=4),\n",
    "                USLaborDay,\n",
    "                # Holiday('Thanksgiving_1DB', month=11, day=1, offset=pd.DateOffset(weekday=WE(4))),\n",
    "                USThanksgivingDay,\n",
    "                # Holiday('Christmas_1DB', month=12, day=24),\n",
    "                Holiday('Christmas', month=12, day=25),\n",
    "                Holiday('New_Years_Eve', month=12, day=31),\n",
    "                ]\n",
    "    return holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def cov2corr(cov):\n",
    "    \"\"\"\n",
    "    Transform a covariance matrix into a correlation matrix. Useful for understanding coefficient correlations\n",
    "    \"\"\"\n",
    "    D = np.sqrt(cov.diagonal()).reshape(-1, 1)\n",
    "    return cov / D / D.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def load_sales_example():\n",
    "    \"\"\"\n",
    "    Read data for the first sales forecasting example\n",
    "    \"\"\"\n",
    "    data_dir = os.path.dirname(os.path.abspath(__file__)) + '/pkg_data/'\n",
    "    return pd.read_csv(data_dir + 'sales.csv', index_col=0)[['Sales', 'Advertising']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def load_sales_example2():\n",
    "    \"\"\"\n",
    "    Read data for the second sales forecasting example\n",
    "    \"\"\"\n",
    "    data_dir = os.path.dirname(os.path.abspath(__file__)) + '/pkg_data/'\n",
    "    data = pd.read_pickle(data_dir + 'sim_sales_data')\n",
    "    data = data.set_index('Date')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def load_dcmm_latent_factor_example():\n",
    "    \"\"\"\n",
    "    Read data for the DCMM latent factor example\n",
    "    \"\"\"\n",
    "    data_dir = os.path.dirname(os.path.abspath(__file__)) + '/pkg_data/'\n",
    "    data = load(data_dir + 'dcmm_latent_factor_data')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def load_dbcm_latent_factor_example():\n",
    "    \"\"\"\n",
    "    Read data for the DBCM latent factor example\n",
    "    \"\"\"\n",
    "    data_dir = os.path.dirname(os.path.abspath(__file__)) + '/pkg_data/'\n",
    "    data = load(data_dir + 'dbcm_latent_factor_data')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def load_dlmm_example():\n",
    "    \"\"\"\n",
    "    Read data for the DBCM latent factor example\n",
    "    \"\"\"\n",
    "    data_dir = os.path.dirname(os.path.abspath(__file__)) + '/pkg_data/'\n",
    "    data = pd.read_csv(data_dir + 'dlmm_example_data.csv')\n",
    "    data.DATE = pd.to_datetime(data.DATE)\n",
    "    data = data.set_index('DATE')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def load_us_inflation():\n",
    "    \"\"\"\n",
    "    Read in quarterly US inflation data\n",
    "    \"\"\"\n",
    "    data_dir = os.path.dirname(os.path.abspath(__file__)) + '/pkg_data/'\n",
    "    data = pd.read_csv(data_dir + 'us_inflation.csv')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def load_us_inflation_forecasts():\n",
    "    \"\"\"\n",
    "    Read in quarterly US inflation data along with forecasts from 4 models\n",
    "    \"\"\"\n",
    "    data_dir = os.path.dirname(os.path.abspath(__file__)) + '/pkg_data/'\n",
    "    \n",
    "    data = pd.read_csv(data_dir + 'bps_inflation.csv')\n",
    "    dates = data.values[:,0]\n",
    "    agent_mean = pd.read_csv(data_dir + 'bps_agent_mean.csv')\n",
    "    agent_mean.columns = ['Dates', '1', '2', '3', '4']\n",
    "    agent_mean.set_index('Dates', inplace=True)\n",
    "    \n",
    "    agent_var = pd.read_csv(data_dir + 'bps_agent_var.csv').values\n",
    "    agent_dof = pd.read_csv(data_dir + 'bps_agent_dof.csv').values\n",
    "    agent_var[:,1:] = agent_var[:,1:] * agent_dof[:,1:] / (agent_dof[:,1:]-2) # Adjust the agent variance for d.o.f. b/c they're t-distributed\n",
    "    agent_var = pd.DataFrame(agent_var)\n",
    "    agent_var.columns = ['Dates', '1', '2', '3', '4']\n",
    "    agent_var.set_index('Dates', inplace=True)\n",
    "    \n",
    "    dates = pd.date_range('1977-09-01', '2014-12-31', freq='3M')\n",
    "    Y = data['Inflation'].values\n",
    "    \n",
    "    data = {'Inflation':Y, 'model_mean':agent_mean, 'model_var':agent_var, 'Dates':dates}\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_dglm.ipynb.\n",
      "Converted 01_update.ipynb.\n",
      "Converted 02_forecast.ipynb.\n",
      "Converted 03_define_models.ipynb.\n",
      "Converted 04_seasonal.ipynb.\n",
      "Converted 05_analysis.ipynb.\n",
      "Converted 06_conjugates.ipynb.\n",
      "Converted 07_point_forecast.ipynb.\n",
      "Converted 08_loss_functions.ipynb.\n",
      "Converted 09_plot.ipynb.\n",
      "Converted 10_shared.ipynb.\n",
      "Converted 11_dcmm.ipynb.\n",
      "Converted 12_dbcm.ipynb.\n",
      "Converted 13_latent_factor.ipynb.\n",
      "Converted 14_latent_factor_fxns.ipynb.\n",
      "Converted 15_dlmm.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
