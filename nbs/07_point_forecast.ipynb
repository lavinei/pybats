{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp point_forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point Forecasts\n",
    "\n",
    "> Functions to find point forecasts using simulated values from the forecast distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forecast samples are the output from `dglm.forecast_marginal`, `dglm.forecast_path`, and most commonly, `analysis`. All of the functions in this module accept an array of forecast samples and produce a series of point forecasts, such as the forecast mean or median.\n",
    "\n",
    "When using `analysis`, the samples are sequentially simulated from the forecast distribution at each specified time step. The forecast samples are placed in a 3 dimensional array, whose axes are *nsamps* $\\times$ *forecast length* $\\times$ *k*, where:\n",
    "- **nsamps** is the number of samples drawn from the forecast distribution\n",
    "- **forecast length** is the number of time steps between `forecast_start` and `forecast_end` in `analysis`\n",
    "- **k** is the forecast horizon, or the number of steps that were forecast ahead\n",
    "\n",
    "The point forecast will be calculated over *nsamps*, meaning that the output will be a 2 dimensional array of size *forecast length* $\\times$ *k*.\n",
    "\n",
    "More generally, all of the point forecasts are calculated from an array and assume that random samples are stored along the first dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#exporti\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "# Optimal for MSE or mean squared error\n",
    "def mean(samps):\n",
    "    \"\"\"\n",
    "    Find the mean point forecasts.\n",
    "    \"\"\"\n",
    "    return np.mean(samps, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean point forecast is theoretically optimal for minimizing squared error loss, $L = \\sum_i (y_i - f_i)^2$.\n",
    "\n",
    "An example below demonstrates how to use the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beginning forecasting\n"
     ]
    }
   ],
   "source": [
    "from pybats.shared import load_us_inflation\n",
    "from pybats.analysis import analysis\n",
    "import pandas as pd\n",
    "\n",
    "data = load_us_inflation()\n",
    "\n",
    "forecast_start = '2000-Q1'\n",
    "forecast_end = '2013-Q4'\n",
    "\n",
    "mod, samples = analysis(Y = data.Inflation.values[1:], X=None, family=\"normal\",\n",
    "                        k = 4, prior_length = 12,\n",
    "                        forecast_start = forecast_start, forecast_end = forecast_end,\n",
    "                        dates=data.Date,\n",
    "                        ntrend = 2, deltrend=.99,\n",
    "                        nsamps = 5000)\n",
    "\n",
    "\n",
    "forecast = mean(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56, 4)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1-Step Ahead</th>\n",
       "      <th>2-Step Ahead</th>\n",
       "      <th>3-Step Ahead</th>\n",
       "      <th>4-Step Ahead</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-01</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-04-01</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-07-01</th>\n",
       "      <td>1.06</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-10-01</th>\n",
       "      <td>1.07</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-01</th>\n",
       "      <td>1.13</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1.04</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            1-Step Ahead  2-Step Ahead  3-Step Ahead  4-Step Ahead\n",
       "Date                                                              \n",
       "2000-01-01          0.99          0.96          0.87          0.80\n",
       "2000-04-01          1.00          0.94          0.88          0.81\n",
       "2000-07-01          1.06          1.01          0.93          0.88\n",
       "2000-10-01          1.07          1.03          0.96          0.97\n",
       "2001-01-01          1.13          1.05          1.04          1.02"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = data[data.Date == forecast_start].index[0]\n",
    "end = data[data.Date == forecast_end].index[0] + 1\n",
    "dates = pd.to_datetime(data[start:end].Date)\n",
    "\n",
    "\n",
    "forecast = pd.DataFrame(forecast, index=dates)\n",
    "forecast.columns = ['1-Step Ahead', '2-Step Ahead', '3-Step Ahead', '4-Step Ahead']\n",
    "forecast.round(2).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The forecasts are made on each date *before* seeing the observation. So the $1-$Step ahead forecast is for the date listed in that row. The $2-$Step Ahead forecast is project the mean for the date listed in the next row, and so on.\n",
    "\n",
    "This view allows you to easily see the forecasts and how the model projects into the future. Looking across the first row, it is clear that the model has a negative local slope, because the forecasts generally decrease as they go further into the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "# Optimal for MAD or absolute deviation\n",
    "def median(samps):\n",
    "    \"\"\"\n",
    "    Find the median point forecasts.\n",
    "    \"\"\"\n",
    "    return np.median(samps, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The median point forecast is theoretically optimal for minimizing absolute deviation loss, $L = \\sum_i |y_i - f_i|$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1-Step Ahead</th>\n",
       "      <th>2-Step Ahead</th>\n",
       "      <th>3-Step Ahead</th>\n",
       "      <th>4-Step Ahead</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-01</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-04-01</th>\n",
       "      <td>1.02</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-07-01</th>\n",
       "      <td>1.04</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-10-01</th>\n",
       "      <td>1.06</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-01</th>\n",
       "      <td>1.13</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            1-Step Ahead  2-Step Ahead  3-Step Ahead  4-Step Ahead\n",
       "Date                                                              \n",
       "2000-01-01          0.97          0.96          0.87          0.80\n",
       "2000-04-01          1.02          0.96          0.90          0.82\n",
       "2000-07-01          1.04          1.00          0.93          0.88\n",
       "2000-10-01          1.06          1.02          0.96          0.99\n",
       "2001-01-01          1.13          1.05          1.05          1.02"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast = median(samples)\n",
    "\n",
    "forecast = pd.DataFrame(forecast, index=dates)\n",
    "forecast.columns = ['1-Step Ahead', '2-Step Ahead', '3-Step Ahead', '4-Step Ahead']\n",
    "forecast.round(2).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "\n",
    "# Utility function\n",
    "def weighted_quantile(samp, weights, quantile=0.5):\n",
    "    order = np.argsort(samp)\n",
    "    ord_samp = samp[order]\n",
    "    ord_weights = weights[order]\n",
    "    lower = ord_samp[np.max(np.where(np.cumsum(ord_weights) < quantile))]\n",
    "    upper = ord_samp[np.min(np.where(np.cumsum(ord_weights) > quantile))]\n",
    "    return (upper + lower) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "# Optimal for APE. Always less than the median. Ignores samples that are 0.\n",
    "def m_one_median(samps):\n",
    "    \"\"\"\n",
    "    Find the (-1)-median point forecasts.\n",
    "    \"\"\"\n",
    "    def m_one_median(samp):\n",
    "        nz = samp.nonzero()[0]\n",
    "        weights = 1/samp[nz]\n",
    "        norm = np.sum(weights)\n",
    "        weights = weights/norm\n",
    "        if len(nz) < 5:\n",
    "            print('Less than 5 non-zero samples')\n",
    "        return weighted_quantile(samp[nz], weights)\n",
    "\n",
    "    forecast = np.apply_along_axis(m_one_median, 0, samps)\n",
    "\n",
    "    return forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $\\left(-1\\right)-$median is theoretically optimal for minimizing absolute percent error, $L=\\sum_i |y_i - f_i|/y_i$. It is always lower than the median, and is only defined for non-zero $y$.\n",
    "\n",
    "We'll use a new example, because the $(-1)-$median can produce strange results when $y_i$ is close to $0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beginning forecasting\n"
     ]
    }
   ],
   "source": [
    "from pybats.shared import load_sales_example\n",
    "\n",
    "data = load_sales_example()             \n",
    "\n",
    "Y = data['Sales'].values\n",
    "X = data['Advertising'].values\n",
    "\n",
    "k = 4                                               \n",
    "forecast_start = 15                                \n",
    "forecast_end = 30                               \n",
    "\n",
    "mod, samples = analysis(Y, X, family=\"poisson\",\n",
    "                        forecast_start=forecast_start, forecast_end=forecast_end,\n",
    "                        k=k, prior_length=6,\n",
    "                        rho=.5, deltrend=0.95, delregn=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1-Step Ahead</th>\n",
       "      <th>2-Step Ahead</th>\n",
       "      <th>3-Step Ahead</th>\n",
       "      <th>4-Step Ahead</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71.5</td>\n",
       "      <td>73.5</td>\n",
       "      <td>47.5</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>29.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1-Step Ahead  2-Step Ahead  3-Step Ahead  4-Step Ahead\n",
       "0          71.5          73.5          47.5          52.0\n",
       "1          68.0          44.0          48.0          39.0\n",
       "2          37.0          39.0          34.0          29.5\n",
       "3          40.0          35.0          30.0          22.0\n",
       "4          31.0          27.0          20.0          19.0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast = m_one_median(samples)\n",
    "\n",
    "forecast = pd.DataFrame(forecast)\n",
    "forecast.columns = ['1-Step Ahead', '2-Step Ahead', '3-Step Ahead', '4-Step Ahead']\n",
    "forecast.round(2).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "\n",
    "# Here we get the joint one_median, where the rows are forecast samples\n",
    "# Assume that the forecast is 'joint' across the second dimension\n",
    "# This is optimal for the WAPE loss, where the denominator in the WAPE score is the sum over the second dimension\n",
    "# If the forecast samples are from a standard analysis function, that will be the sum over all forecast dates\n",
    "def joint_m_one_median(samps):\n",
    "\n",
    "    def joint_m_one_median(samp):\n",
    "        rows, cols = samp.shape\n",
    "        # Remove rows that are all zero\n",
    "        rowsums = np.sum(samp, axis=1)\n",
    "        psamp = samp[rowsums.nonzero()[0], :]\n",
    "        rowsums = rowsums[rowsums.nonzero()[0]]\n",
    "\n",
    "        # Weight each joint sample (i.e. row) by the inverse of its sum\n",
    "        weights = 1 / rowsums\n",
    "        norm = np.sum(weights)\n",
    "        weights = weights / norm\n",
    "\n",
    "        # Get the -1 median for each column using these joint weights\n",
    "        forecast = np.zeros(cols)\n",
    "        for c in range(cols):\n",
    "            forecast[c] = weighted_quantile(psamp[:, c], weights)\n",
    "\n",
    "        return forecast\n",
    "\n",
    "    if samps.ndim == 2:\n",
    "        return joint_m_one_median(samps)\n",
    "    elif samps.ndim == 3:\n",
    "        return np.array(list(map(joint_m_one_median, samps.transpose([1,0,2]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "\n",
    "# For the constrained point forecasts\n",
    "# F is a vector of constraints for the totals across the 3rd dimension of 'samps'\n",
    "# Expected dimensions are: nsamps x time x (forecast horizon or items)\n",
    "def constrained_mean(samps, F):\n",
    "    means = np.mean(samps, axis=0)\n",
    "    n = means.shape[1]\n",
    "    diff = (F - np.sum(means, axis=1))/n\n",
    "    return means + diff.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "\n",
    "def constrained_median(samps, F):\n",
    "    if samps.ndim == 2:\n",
    "        samps = np.expand_dims(samps, axis=1)\n",
    "\n",
    "    # Initialize values\n",
    "    forecast = median(samps)\n",
    "    times = forecast.shape[0]\n",
    "    lambd = np.zeros(times)\n",
    "\n",
    "    # Iterate until a solution is found for each lambda\n",
    "    tol = 1\n",
    "    eps = 1E-2\n",
    "    max_shift = 5E-2\n",
    "    iter = 0\n",
    "    max_iter = 50\n",
    "    diff = F - np.sum(forecast, axis=1)\n",
    "    test = np.abs(diff) > tol\n",
    "\n",
    "    while np.any(test):\n",
    "        shift = np.abs(eps*diff)\n",
    "        shift[shift > max_shift] = max_shift\n",
    "        lambd = lambd + np.sign(diff)*shift\n",
    "        percentiles = 100*(1+lambd)/2\n",
    "        for idx, p in enumerate(percentiles):\n",
    "            if test[idx]:\n",
    "                forecast[idx,:] = np.percentile(samps[:,idx,:], p, axis=0, interpolation='nearest')\n",
    "        diff = F - np.sum(forecast, axis=1)\n",
    "        test = np.abs(diff) > tol\n",
    "        iter += 1\n",
    "        if iter > max_iter:\n",
    "           break\n",
    "    return forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "\n",
    "def constrained_joint_m_one_median(samps, F):\n",
    "\n",
    "\n",
    "    def constrained_joint_m_one_median(samp, F):\n",
    "        #if samp.ndim == 2:\n",
    "        #    samp = np.expand_dims(samp, axis=1)\n",
    "\n",
    "        # Remove joint samples that are all 0\n",
    "        rowsums = np.sum(samp, axis=1)\n",
    "        nz = rowsums.nonzero()[0]\n",
    "        samp = samp[nz,:]\n",
    "        rowsums = rowsums[nz]\n",
    "        # Find weights\n",
    "        weights = 1 / rowsums\n",
    "        norm = np.sum(weights)\n",
    "        weights = weights / norm\n",
    "\n",
    "        # Initialize value\n",
    "        forecast = joint_m_one_median(samp).reshape(1,-1)\n",
    "        times = forecast.shape[0]\n",
    "        lambd = np.zeros(times)\n",
    "\n",
    "        # Iterate until a solution is found for each lambda\n",
    "        tol = 1\n",
    "        eps = 1E-2\n",
    "        max_shift = 5E-2\n",
    "        iter = 0\n",
    "        max_iter = 50\n",
    "        diff = F - np.sum(forecast)\n",
    "        test = np.abs(diff) > tol\n",
    "\n",
    "        while np.any(test):\n",
    "            shift = np.abs(eps * diff)\n",
    "            if shift > max_shift:\n",
    "                shift = max_shift\n",
    "            lambd = lambd + np.sign(diff) * shift\n",
    "            percentile = 100 * (1 + lambd) / 2\n",
    "            forecast = np.array(list(map(lambda s: weighted_quantile(s, weights, percentile/100),\n",
    "                                                 samp.T)))\n",
    "            diff = F - np.sum(forecast)\n",
    "            test = np.abs(diff) > tol\n",
    "            iter += 1\n",
    "            if iter > max_iter:\n",
    "                break\n",
    "        return forecast.reshape(1,-1)\n",
    "\n",
    "    if samps.ndim == 2:\n",
    "        samps = np.expand_dims(samps, axis=1)\n",
    "\n",
    "    return np.array(list(map(lambda samp, F: constrained_joint_m_one_median(samp, F),\n",
    "                             samps.transpose([1, 0, 2]),\n",
    "                             F)))[:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "\n",
    "# Optimal for ZAPE. Always less than the (-1)-median.\n",
    "def zape_point_estimate(samps):\n",
    "    \"\"\"\n",
    "    Return the optimal point forecast for ZAPE loss, given samples from the analysis function.\n",
    "\n",
    "    This forecast is theoretically optimal for minimizing ZAPE loss, which is defined as:\n",
    "\n",
    "    .. math:: ZAPE(y, f) = \\\\frac{1}{n} \\sum_{i=1:n} I(y_i = 0) * f_i + I(y_i = 1) * |y_i-f_i| / y_i\n",
    "\n",
    "    :param samps: Forecast samples, returned from the analysis function. Will have 3-dimensions (nsamps * time * forecast horizon)\n",
    "    :return: Array of (-1)-median forecasts. Will have dimension (time * forecast horizon)\n",
    "    \"\"\"\n",
    "    def est_c_hat(samp):\n",
    "        nz = samp.nonzero()[0]\n",
    "        weights = 1/samp[nz]\n",
    "        c_hat = 1 / (1/len(nz) * np.sum(weights))\n",
    "        return c_hat\n",
    "\n",
    "    def zape_point_est(samp):\n",
    "        nz = samp.nonzero()[0]\n",
    "        pi_0 = len(nz) / len(samp) # probability of 0\n",
    "        weights = 1 / samp[nz]\n",
    "        norm = np.sum(weights)\n",
    "        weights = weights / norm\n",
    "        c_hat = est_c_hat(samp)\n",
    "        quantile = (1 - c_hat*pi_0)/2\n",
    "\n",
    "        return weighted_quantile(samp[nz], weights, quantile)\n",
    "\n",
    "    forecast = np.apply_along_axis(m_one_median, 0, samps)\n",
    "\n",
    "    return forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_dglm.ipynb.\n",
      "Converted 01_update.ipynb.\n",
      "Converted 02_forecast.ipynb.\n",
      "Converted 03_define_models.ipynb.\n",
      "Converted 04_seasonal.ipynb.\n",
      "Converted 05_analysis.ipynb.\n",
      "Converted 06_conjugates.ipynb.\n",
      "Converted 07_point_forecast.ipynb.\n",
      "Converted 08_loss_functions.ipynb.\n",
      "Converted 09_plot.ipynb.\n",
      "Converted 10_shared.ipynb.\n",
      "Converted 11_dcmm.ipynb.\n",
      "Converted 12_dbcm.ipynb.\n",
      "Converted 13_latent_factor.ipynb.\n",
      "Converted 14_latent_factor_fxns.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
