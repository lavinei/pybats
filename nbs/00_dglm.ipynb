{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp dglm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DGLM\n",
    "\n",
    "> The class Dynamic Generalized Linear Model (DGLM), which is the core of the PyBATS package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PyBATS library supports many types of DGLMs - Poisson, Bernoulli, Normal (a DLM), and Binomial.\n",
    "\n",
    "A Dynamic Generalized Linear Model is defined by:\n",
    "- The exponential family of the observations $y_t$: Normal, Poisson, Bernoulli, or Binomial\n",
    "- The components in the state vector: Trend, Regression, Seasonal, Holiday, and Latent Factor\n",
    "\n",
    "A DGLM is a linear state space model, defined by the dynamic regression:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "y_t &\\sim p(\\lambda_t) \\\\\n",
    "\\lambda_{t} &= F_{t}' \\theta_{t}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $p(\\lambda_t)$ is the forecast distribution for the observation $y_t$\n",
    "- $\\theta_t$ is the state vector, containing the model coefficients\n",
    "- $F_t$ is the regression vector, containing all of the predictors $X_t$\n",
    "\n",
    "A PyBATS DGLM has three core methods. \n",
    "\n",
    "- `dglm.update` updates the state vector $\\theta_t$ after observing $y_t$. \n",
    "- `dglm.forecast_marginal` simulates from the forecast distribution for $y_{t+k}$,  $k$ time steps into the future. \n",
    "- `dglm.forecast_path` simulates from the joint forecast distribution for $y_{t+1}:y_{t+k}$ from today through to $k$ steps into the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "from nbdev.showdoc import *\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import pandas as pd\n",
    "from collections.abc import Iterable\n",
    "\n",
    "from pybats.latent_factor_fxns import update_lf_analytic, update_lf_sample, forecast_marginal_lf_analytic, \\\n",
    "    forecast_marginal_lf_sample, forecast_path_lf_copula, forecast_path_lf_sample, get_mean_and_var_lf, \\\n",
    "    get_mean_and_var_lf_dlm, update_lf_analytic_dlm\n",
    "from pybats.seasonal import seascomp, createFourierToSeasonalL\n",
    "from pybats.update import update, update_dlm, update_bindglm\n",
    "from pybats.forecast import forecast_marginal, forecast_path, forecast_path_copula,\\\n",
    "    forecast_marginal_bindglm, forecast_path_dlm, forecast_state_mean_and_var\n",
    "from pybats.conjugates import trigamma, bern_conjugate_params, bin_conjugate_params, pois_conjugate_params\n",
    "\n",
    "# These are for the bernoulli and Poisson DGLMs\n",
    "from scipy.special import digamma\n",
    "from scipy.special import beta as beta_fxn\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class dglm:\n",
    "\n",
    "    def __init__(self,\n",
    "                 a0=None,\n",
    "                 R0=None,\n",
    "                 nregn=0,\n",
    "                 ntrend=0,\n",
    "                 nlf=0,\n",
    "                 nhol=0,\n",
    "                 seasPeriods=[],\n",
    "                 seasHarmComponents=[],\n",
    "                 deltrend=1, delregn=1,\n",
    "                 dellf=1,\n",
    "                 delhol=1, delseas=1,\n",
    "                 rho=1,\n",
    "                 interpolate=True,\n",
    "                 adapt_discount=False,\n",
    "                 adapt_factor=0.5,\n",
    "                 discount_forecast=False):\n",
    "        \"\"\"\n",
    "        A Dynamic Generalized Linear Model (DGLM). Generic Class. Children include Poisson, Bernoulli, and Binomial DGLMs, as well as the Normal DLM.\n",
    "\n",
    "        :param a0: Prior mean vector\n",
    "        :param R0: Prior covariance matrix\n",
    "        :param nregn: Number of regression components\n",
    "        :param ntrend: Number of trend components\n",
    "        :param nhol: Number of holiday components\n",
    "        :param seasPeriods: List of periods of seasonal components\n",
    "        :param seasHarmComponents: List of harmonic components included for each period\n",
    "        :param deltrend: Discount factor on trend components\n",
    "        :param delregn: Discount factor on regression components\n",
    "        :param delhol: Discount factor on holiday components (currently deprecated)\n",
    "        :param delseas: Discount factor on seasonal components\n",
    "        :param interpolate: Whether to use interpolation for conjugate parameters (provides a computational speedup)\n",
    "        :param adapt_discount: What method of discount adaption. False = None, 'positive_regn' = only discount if regression information is available, 'info' = information based,\\\n",
    "        :param adapt_factor: If adapt_discount='info', then a higher value adapt_factor leads to a quicker adaptation (with less discounting) on overly uncertain parameters\n",
    "        :param discount_forecast: Whether to use discounting when forecasting\n",
    "        :return An object of class dglm\n",
    "        \"\"\"\n",
    "\n",
    "        # Setting up trend F, G matrices\n",
    "\n",
    "        i = 0\n",
    "        self.itrend = list(range(i, ntrend))\n",
    "        i += ntrend\n",
    "        if ntrend == 0:\n",
    "            Gtrend = np.empty([0, 0])\n",
    "            Ftrend = np.zeros([ntrend]).reshape(-1, 1)\n",
    "        # Local level\n",
    "        elif ntrend == 1:\n",
    "            Gtrend = np.identity(ntrend)\n",
    "            Ftrend = np.array([1]).reshape(-1, 1)\n",
    "        # Locally linear\n",
    "        elif ntrend == 2:\n",
    "            Gtrend = np.array([[1, 1], [0, 1]])\n",
    "            Ftrend = np.array([1, 0]).reshape(-1, 1)\n",
    "\n",
    "        # Setting up regression F, G matrices\n",
    "        self.iregn = list(range(i, i + nregn))\n",
    "        if nregn == 0:\n",
    "            Fregn = np.empty([0]).reshape(-1, 1)\n",
    "            Gregn = np.empty([0, 0])\n",
    "        else:\n",
    "            Gregn = np.identity(nregn)\n",
    "            Fregn = np.ones([nregn]).reshape(-1, 1)\n",
    "            i += nregn\n",
    "\n",
    "        # Setting up holiday F, G matrices (additional regression indicators components)\n",
    "        self.ihol = list(range(i, i + nhol))\n",
    "        self.iregn.extend(self.ihol)  # Adding on to the self.iregn\n",
    "        if nhol == 0:\n",
    "            Fhol = np.empty([0]).reshape(-1, 1)\n",
    "            Ghol = np.empty([0, 0])\n",
    "        else:\n",
    "            Ghol = np.identity(nhol)\n",
    "            Fhol = np.ones([nhol]).reshape(-1, 1)\n",
    "            i += nhol\n",
    "\n",
    "        # Setting up seasonal F, G matrices\n",
    "        self.iseas = []\n",
    "        if len(seasPeriods) == 0:\n",
    "            Fseas = np.empty([0]).reshape(-1, 1)\n",
    "            Gseas = np.empty([0, 0])\n",
    "            nseas = 0\n",
    "        else:\n",
    "            output = list(map(seascomp, seasPeriods, seasHarmComponents))\n",
    "            Flist = [x[0] for x in output]\n",
    "            Glist = [x[1] for x in output]\n",
    "            self.L = list(map(createFourierToSeasonalL, seasPeriods, seasHarmComponents, Flist, Glist))\n",
    "            nseas = 2 * sum(map(len, seasHarmComponents))\n",
    "            Fseas = np.zeros([nseas]).reshape(-1, 1)\n",
    "            Gseas = np.zeros([nseas, nseas])\n",
    "            idx = 0\n",
    "            for harmComponents in seasHarmComponents:\n",
    "                self.iseas.append(list(range(i, i + 2 * len(harmComponents))))\n",
    "                i += 2 * len(harmComponents)\n",
    "            for Fs, Gs in output:\n",
    "                idx2 = idx + Fs.shape[0]\n",
    "                Fseas[idx:idx2, 0] = Fs.squeeze()\n",
    "                Gseas[idx:idx2, idx:idx2] = Gs\n",
    "                idx = idx2\n",
    "\n",
    "        # Setting up the latent factor F, G matrices\n",
    "        if nlf == 0:\n",
    "            self.latent_factor = False\n",
    "            Glf = np.empty([0, 0])\n",
    "            Flf = np.zeros([0]).reshape(-1, 1)\n",
    "        else:\n",
    "            self.latent_factor = True\n",
    "            Glf = np.identity(nlf)\n",
    "            Flf = np.ones([nlf]).reshape(-1, 1)\n",
    "            self.ilf = list(range(i, i + nlf))\n",
    "            i += nlf\n",
    "\n",
    "        # Combine the F and G components together\n",
    "        F = np.vstack([Ftrend, Fregn, Fhol, Fseas, Flf])\n",
    "        G = sc.linalg.block_diag(Gtrend, Gregn, Ghol, Gseas, Glf)\n",
    "\n",
    "        # store the discount info\n",
    "        self.deltrend = deltrend\n",
    "        self.delregn = delregn\n",
    "        self.delhol = delhol\n",
    "        self.delseas = delseas\n",
    "        self.dellf = dellf\n",
    "\n",
    "        # Random effect to inflate variance (if rho < 1)\n",
    "        self.rho = rho\n",
    "\n",
    "        self.ntrend = ntrend\n",
    "        self.nregn = nregn + nhol  # Adding on nhol\n",
    "        self.nregn_exhol = nregn\n",
    "        self.nhol = nhol\n",
    "        self.nseas = nseas\n",
    "        self.nlf = nlf\n",
    "\n",
    "        self.adapt_discount = adapt_discount\n",
    "        self.k = adapt_factor\n",
    "\n",
    "        # Set up discount matrix\n",
    "        self.discount_forecast = discount_forecast\n",
    "        Discount = self.build_discount_matrix()\n",
    "        self.Discount = Discount\n",
    "\n",
    "        self.param1 = 2  # Random initial guess\n",
    "        self.param2 = 2  # Random initial guess\n",
    "\n",
    "\n",
    "        self.seasPeriods = seasPeriods\n",
    "        self.seasHarmComponents = seasHarmComponents\n",
    "        self.F = F\n",
    "        self.G = G\n",
    "        self.a = a0.reshape(-1, 1)\n",
    "        self.R = R0\n",
    "        self.t = 0\n",
    "        self.interpolate = interpolate\n",
    "        self.W = self.get_W()\n",
    "\n",
    "    def build_discount_matrix(self, X=None, phi_mu=None):\n",
    "        # build up discount factors while possibly taking special care to not discount when the \"regn\"\n",
    "        # type factors are zero\n",
    "\n",
    "        # do this all with matrix slicing which is much faster than the block diag\n",
    "        p = np.sum([self.ntrend, self.nregn_exhol, self.nhol, self.nseas, self.nlf])\n",
    "        # start with no discounting\n",
    "        component_discounts = np.ones([p, p])\n",
    "        i = 0 # this will be the offset of the current block\n",
    "        for discount_pair, n in zip([('std', self.deltrend), ('regn', self.delregn), ('hol', self.delhol),\n",
    "                                     ('std', self.delseas), ('lf', self.dellf)],\n",
    "                                    [self.ntrend, self.nregn_exhol, self.nhol, self.nseas, self.nlf]):\n",
    "            discount_type, discount = discount_pair\n",
    "            if n > 0:\n",
    "                if isinstance(discount, Iterable):\n",
    "                    if len(discount) < n:\n",
    "                        raise ValueError('Error: Length of discount factors must be 1 or match component length')\n",
    "                    for j, disc in enumerate(discount[:n]):\n",
    "                        # fill the diags one at a time\n",
    "                        component_discounts[i+j, i+j] = disc\n",
    "                else:\n",
    "                    # fill the block with the constant\n",
    "                    component_discounts[i:(i+n), i:(i+n)] = discount\n",
    "\n",
    "                # overwrite with ones if doing the positive logic\n",
    "                if X is not None and self.adapt_discount == 'positive_regn' and (discount_type == 'regn' or discount_type == 'hol'):\n",
    "                    if not isinstance(X, Iterable):\n",
    "                        X = [X]\n",
    "\n",
    "                    if discount_type == 'regn':\n",
    "                        # offset of the regression params\n",
    "                        regn_i = 0\n",
    "                    elif discount_type == 'hol':\n",
    "                        regn_i = self.nregn_exhol\n",
    "                    # look through the regression params and set that slice on the\n",
    "                    # discount to 1 if 0\n",
    "                    for j in range(n):\n",
    "                        if X[regn_i] == 0:\n",
    "                            # set all discounts to one (i offsets the block and j offsets the regn param)\n",
    "                            component_discounts[i + j, :] = 1.\n",
    "                            component_discounts[:, i + j] = 1.\n",
    "                        regn_i += 1\n",
    "\n",
    "                if phi_mu is not None and self.adapt_discount == 'positive_regn' and discount_type == 'lf':\n",
    "                    # offset of the latent factor params\n",
    "                    lf_i = 0\n",
    "                    # look through the latent factor params and set that slice on the\n",
    "                    # discount to 1 if 0\n",
    "                    for j in range(n):\n",
    "                        if phi_mu[lf_i] == 0:\n",
    "                            # set all discounts to one (i offsets the block and j offsets the regn param)\n",
    "                            component_discounts[i + j, :] = 1.\n",
    "                            component_discounts[:, i + j] = 1.\n",
    "                        lf_i += 1\n",
    "\n",
    "                # move on to the next block\n",
    "                i += n\n",
    "\n",
    "        return component_discounts\n",
    "\n",
    "    def update(self, y=None, X=None, phi_mu = None, phi_sigma = None, analytic=True, phi_samps=None, **kwargs):\n",
    "        \"\"\"\n",
    "        Update the DGLM state vector mean and covariance after observing 'y', with covariates 'X'.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.latent_factor:\n",
    "            if analytic:\n",
    "                update_lf_analytic(self, y, X, phi_mu, phi_sigma)\n",
    "            else:\n",
    "                parallel = kwargs.get('parallel')\n",
    "                if parallel is None: parallel = False\n",
    "                update_lf_sample(self, y, X, phi_samps, parallel)\n",
    "        else:\n",
    "            update(self, y, X)\n",
    "\n",
    "    def forecast_marginal(self, k, X=None, nsamps=1, mean_only=False,\n",
    "                          phi_mu = None, phi_sigma=None, analytic=True, phi_samps=None,\n",
    "                          state_mean_var=False, y=None):\n",
    "        \"\"\"\n",
    "        Simulate from the forecast distribution at time *t+k*.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.latent_factor:\n",
    "            if analytic:\n",
    "                return forecast_marginal_lf_analytic(self, k, X, phi_mu, phi_sigma, nsamps, mean_only, state_mean_var)\n",
    "            else:\n",
    "                forecast_marginal_lf_sample(self, k, X, phi_samps, mean_only)\n",
    "        else:\n",
    "            return forecast_marginal(self, k, X, nsamps, mean_only, state_mean_var, y)\n",
    "\n",
    "    def forecast_path(self, k, X=None, nsamps=1, copula=True,\n",
    "                      phi_mu=None, phi_sigma=None, phi_psi=None, analytic=True, phi_samps=None,\n",
    "                      **kwargs):\n",
    "        \"\"\"\n",
    "        Simulate from the path (joint) forecast distribution from *1* to *k* steps ahead.\n",
    "        \"\"\"\n",
    "        if self.latent_factor:\n",
    "            if analytic:\n",
    "                return forecast_path_lf_copula(self, k, X, phi_mu, phi_sigma, phi_psi, nsamps, **kwargs)\n",
    "            else:\n",
    "                return forecast_path_lf_sample(self, k, X, phi_samps)\n",
    "        else:\n",
    "            if copula:\n",
    "                return forecast_path_copula(self, k, X, nsamps, **kwargs)\n",
    "            else:\n",
    "                return forecast_path(self, k, X, nsamps)\n",
    "\n",
    "    def forecast_path_copula(self, k, X=None, nsamps=1, **kwargs):\n",
    "        return forecast_path_copula(self, k, X, nsamps, **kwargs)\n",
    "\n",
    "    # Define specific update and forecast functions, which advanced users can access manually\n",
    "    def update_lf_sample(self, y=None, X=None, phi_samps=None, parallel=False):\n",
    "        update_lf_sample(self, y, X, phi_samps, parallel)\n",
    "\n",
    "    def update_lf_analytic(self, y=None, X=None, phi_mu=None, phi_sigma=None):\n",
    "        update_lf_analytic(self, y, X, phi_mu, phi_sigma)\n",
    "\n",
    "    def forecast_marginal_lf_analytic(self, k, X=None, phi_mu=None, phi_sigma=None, nsamps=1, mean_only=False, state_mean_var=False):\n",
    "        return forecast_marginal_lf_analytic(self, k, X, phi_mu, phi_sigma, nsamps, mean_only, state_mean_var)\n",
    "\n",
    "    def forecast_marginal_lf_sample(self, k, X=None, phi_samps=None, mean_only=False):\n",
    "        return forecast_marginal_lf_sample(self, k, X, phi_samps, mean_only)\n",
    "\n",
    "    def forecast_path_lf_copula(self, k, X=None, phi_mu=None, phi_sigma=None, phi_psi=None, nsamps=1, **kwargs):\n",
    "        return forecast_path_lf_copula(self, k, X, phi_mu, phi_sigma, phi_psi, nsamps, **kwargs)\n",
    "\n",
    "    def forecast_path_lf_sample(self, k, X=None, phi_samps=None, nsamps=1, **kwargs):\n",
    "        return forecast_path_lf_sample(self, k, X, phi_samps)\n",
    "\n",
    "    def forecast_state_mean_and_var(self, k, X = None):\n",
    "        return forecast_state_mean_and_var(self, k, X)\n",
    "\n",
    "    def get_mean_and_var(self, F, a, R):\n",
    "        mean, var = F.T @ a, F.T @ R @ F / self.rho\n",
    "        return np.ravel(mean)[0], np.ravel(var)[0]\n",
    "\n",
    "    def get_mean_and_var_lf(self, F, a, R, phi_mu, phi_sigma, ilf):\n",
    "        return get_mean_and_var_lf(self, F, a, R, phi_mu, phi_sigma, ilf)\n",
    "\n",
    "    def get_W(self, X=None):\n",
    "        if self.adapt_discount == 'info':\n",
    "            info = np.abs(self.a.flatten() / np.sqrt(self.R.diagonal()))\n",
    "            diag = self.Discount.diagonal()\n",
    "            diag = np.round(diag + (1 - diag) * np.exp(-self.k * info), 5)\n",
    "            Discount = np.ones(self.Discount.shape)\n",
    "            np.fill_diagonal(Discount, diag)\n",
    "        elif self.adapt_discount == 'positive_regn' and X is not None:\n",
    "            Discount = self.build_discount_matrix(X)\n",
    "        else:\n",
    "            Discount = self.Discount\n",
    "        return self.R / Discount - self.R\n",
    "    \n",
    "    def get_coef(self, component=None):\n",
    "        \"\"\"Return the coefficient (state vector) means and standard deviations.\n",
    "        \n",
    "        If component=None, then the full state vector is returned.\n",
    "        \n",
    "        Otherwise, specify a single component from 'trend', 'regn', 'seas', 'hol', and 'lf'.\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        trend_names = ['Intercept', 'Local Slope'][:self.ntrend]\n",
    "        regn_names = ['Regn ' + str(i) for i in range(1, self.nregn_exhol+1)]\n",
    "        seas_names = ['Seas ' + str(i) for i in range(1, self.nseas+1)]\n",
    "        hol_names = ['Hol ' + str(i) for i in range(1, self.nhol+1)]\n",
    "        lf_names = ['LF ' + str(i) for i in range(1, self.nlf+1)]\n",
    "\n",
    "        if component is None:\n",
    "\n",
    "            names = [*trend_names, *regn_names, *seas_names, *hol_names, *lf_names]\n",
    "\n",
    "            return pd.DataFrame({'Mean':self.a.reshape(-1),\n",
    "                                 'Standard Deviation': np.sqrt(self.R.diagonal())},\n",
    "                                 index=names).round(2)\n",
    "        elif component == 'trend':\n",
    "            names = trend_names\n",
    "\n",
    "            return pd.DataFrame({'Mean':self.a.reshape(-1)[self.itrend],\n",
    "                                 'Standard Deviation': np.sqrt(self.R.diagonal())[self.itrend]},\n",
    "                                 index=names).round(2)\n",
    "\n",
    "        elif component == 'regn':\n",
    "            names = regn_names\n",
    "\n",
    "            return pd.DataFrame({'Mean':self.a.reshape(-1)[self.iregn],\n",
    "                                 'Standard Deviation': np.sqrt(self.R.diagonal())[self.iregn]},\n",
    "                                 index=names).round(2)\n",
    "\n",
    "        elif component == 'seas':\n",
    "            names = seas_names\n",
    "            \n",
    "            seas_idx = []\n",
    "            for idx in self.iseas:\n",
    "                seas_idx.extend(idx)\n",
    "\n",
    "            return pd.DataFrame({'Mean':self.a.reshape(-1)[seas_idx],\n",
    "                                 'Standard Deviation': np.sqrt(self.R.diagonal())[seas_idx]},\n",
    "                                 index=names).round(2)\n",
    "\n",
    "        elif component == 'hol':\n",
    "            names = hol_names\n",
    "\n",
    "            return pd.DataFrame({'Mean':self.a.reshape(-1)[self.ihol],\n",
    "                                 'Standard Deviation': np.sqrt(self.R.diagonal())[self.ihol]},\n",
    "                                 index=names).round(2)\n",
    "\n",
    "        elif component == 'lf':\n",
    "            names = lf_names\n",
    "\n",
    "            return pd.DataFrame({'Mean':self.a.reshape(-1)[self.ilf],\n",
    "                                 'Standard Deviation': np.sqrt(self.R.diagonal())[self.ilf]},\n",
    "                                 index=names).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a very simple example of manually defining a DGLM. However, in most situations, DGLMs will be defined automatically through `analysis` or through `define_models`.\n",
    "\n",
    "This model has 1 trend coefficent and 2 regression coefficients. The trend is simply an intercept. The 2 regression coefficients mean that we have 2 predictor variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pybats.dglm import pois_dglm\n",
    "\n",
    "a = np.array([1, 1, 1])\n",
    "R = np.eye(3)\n",
    "mod = pois_dglm(a, R, ntrend=1, nregn=2, deltrend=1, delregn=.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Standard Deviation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Intercept</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regn 1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regn 2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Mean  Standard Deviation\n",
       "Intercept     1                 1.0\n",
       "Regn 1        1                 1.0\n",
       "Regn 2        1                 1.0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.get_coef()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`mod.get_coef` provides the mean and standard deviation of the state vector $\\theta$. The mean vector and full variance matrix is also available using `mod.a` and `mod.R`.\n",
    "\n",
    "`deltrend` is the discount factor on the trend component. A discount factor of 1 indicates no expected change over time.\n",
    "\n",
    "`delregn` is the discount factor on the regression component. A discount factor of 0.9 indicates that we expect about a 10% change in the coefficient every time step. This is a very low discount factor. Most of the time, discount factors should be set between $0.95 - 1$.\n",
    "\n",
    "Discounting old information is what makes this model *dynamic*, because we are telling the model that the coefficients should change over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"dglm.update\" class=\"doc_header\"><code>dglm.update</code><a href=\"__main__.py#L219\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>dglm.update</code>(**`y`**=*`None`*, **`X`**=*`None`*, **`phi_mu`**=*`None`*, **`phi_sigma`**=*`None`*, **`analytic`**=*`True`*, **`phi_samps`**=*`None`*, **\\*\\*`kwargs`**)\n",
       "\n",
       "Update the DGLM state vector mean and covariance after observing 'y', with covariates 'X'."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(dglm.update)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will make up an observation $y$ and predictors $X$ and demonstrate how the model updates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 5\n",
    "X = np.array([1,2])\n",
    "mod.update(y = y, X = X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we'll see how the mean and variance of the state vector $\\theta_t$ has now changed from the initial definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Standard Deviation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Intercept</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regn 1</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regn 2</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Mean  Standard Deviation\n",
       "Intercept   0.6                0.92\n",
       "Regn 1      0.6                0.97\n",
       "Regn 2      0.2                0.63"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.get_coef()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"dglm.forecast_marginal\" class=\"doc_header\"><code>dglm.forecast_marginal</code><a href=\"__main__.py#L234\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>dglm.forecast_marginal</code>(**`k`**, **`X`**=*`None`*, **`nsamps`**=*`1`*, **`mean_only`**=*`False`*, **`phi_mu`**=*`None`*, **`phi_sigma`**=*`None`*, **`analytic`**=*`True`*, **`phi_samps`**=*`None`*, **`state_mean_var`**=*`False`*, **`y`**=*`None`*)\n",
       "\n",
       "Simulate from the forecast distribution at time *t+k*."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(dglm.forecast_marginal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can forecast from this model using future values of our predictors, `X_future`. The output are simulated values from the forecast distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17, 10, 51, 10, 21, 10, 21, 11, 19, 20])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_future = np.array([2,1])\n",
    "forecast_samples = mod.forecast_marginal(k = 1, X = X_future, nsamps=1000)\n",
    "forecast_samples[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"dglm.forecast_path\" class=\"doc_header\"><code>dglm.forecast_path</code><a href=\"__main__.py#L249\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>dglm.forecast_path</code>(**`k`**, **`X`**=*`None`*, **`nsamps`**=*`1`*, **`copula`**=*`True`*, **`phi_mu`**=*`None`*, **`phi_sigma`**=*`None`*, **`phi_psi`**=*`None`*, **`analytic`**=*`True`*, **`phi_samps`**=*`None`*, **\\*\\*`kwargs`**)\n",
       "\n",
       "Simulate from the path (joint) forecast distribution from *1* to *k* steps ahead."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(dglm.forecast_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Path forecasting is used to forecast over multiple step steps at once. For example, let's forecast the next 3 time steps. `X_future` is still the future values of our predictors, but it now has 3 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[47, 40, 12],\n",
       "       [25, 19,  4],\n",
       "       [54, 42,  6],\n",
       "       [20, 10,  6],\n",
       "       [ 3,  8,  4],\n",
       "       [10, 10, 10],\n",
       "       [40, 36,  8],\n",
       "       [ 5,  5,  1],\n",
       "       [ 0,  1,  1],\n",
       "       [11,  6,  2]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_future = np.array([[2,1], [2,2], [1,1]])\n",
    "forecast_samples = mod.forecast_path(k = 3, X = X_future, nsamps=1000)\n",
    "forecast_samples[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class bern_dglm(dglm):\n",
    "\n",
    "    def get_conjugate_params(self, ft, qt, alpha_init, beta_init):\n",
    "        # Choose conjugate prior, beta, and match mean & variance\n",
    "        return bern_conjugate_params(ft, qt, alpha_init, beta_init, interp=self.interpolate)\n",
    "\n",
    "    def update_conjugate_params(self, y, alpha, beta):\n",
    "        # Update alpha and beta to the conjugate posterior coefficients\n",
    "        alpha = alpha + y\n",
    "        beta = beta + 1 - y\n",
    "\n",
    "        # Get updated ft* and qt*\n",
    "        ft_star = digamma(alpha) - digamma(beta)\n",
    "        qt_star = trigamma(alpha) + trigamma(beta)\n",
    "\n",
    "        # constrain this thing from going to crazy places\n",
    "        ft_star = max(-8, min(ft_star, 8))\n",
    "        qt_star = max(0.001 ** 2, min(qt_star, 4 ** 2))\n",
    "\n",
    "        return alpha, beta, ft_star, qt_star\n",
    "\n",
    "    def simulate(self, alpha, beta, nsamps):\n",
    "        p = np.random.beta(alpha, beta, [nsamps])\n",
    "        return np.random.binomial(1, p, size=[nsamps])\n",
    "\n",
    "    def simulate_from_sampling_model(self, p, nsamps):\n",
    "        return np.random.binomial(1, p, [nsamps])\n",
    "\n",
    "    def simulate_from_prior(self, alpha, beta, nsamps):\n",
    "        return stats.beta.rvs(a=alpha, b=beta, size=nsamps)\n",
    "\n",
    "    def prior_inverse_cdf(self, cdf, alpha, beta):\n",
    "        return stats.beta.ppf(cdf, alpha, beta)\n",
    "\n",
    "    def sampling_density(self, y, p):\n",
    "        return stats.binom.pmf(n=1, p=p, k=y)\n",
    "\n",
    "    def marginal_cdf(self, y, alpha, beta):\n",
    "        if y == 1:\n",
    "            return 1\n",
    "        elif y == 0:\n",
    "            return beta_fxn(y + alpha, 1 - y + beta) / beta_fxn(alpha, beta)\n",
    "\n",
    "    def loglik(self, y, alpha, beta):\n",
    "        return stats.bernoulli.logpmf(y, alpha / (alpha + beta))\n",
    "\n",
    "    def get_mean(self, alpha, beta):\n",
    "        return np.ravel(alpha / (alpha + beta))[0]\n",
    "\n",
    "    def get_prior_var(self, alpha, beta):\n",
    "        return (alpha * beta) / ((alpha + beta) ** 2 * (alpha + beta + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Bernoulli DGLM models $0-1$ observations:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "y_t &\\sim Bern(\\pi_t) \\\\\n",
    "\\pi_t &= 1/(1 + e^{-\\lambda_t}) \\\\\n",
    "\\lambda_{t} &= F_{t}' \\theta_{t}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Where\n",
    "- Bern($\\pi_t$) is the [Bernoulli distribution](https://en.wikipedia.org/wiki/Bernoulli_distribution) with probability $\\pi_t$\n",
    "- $\\lambda_t$ is transformed through the [logistic function](https://en.wikipedia.org/wiki/Logistic_function) to become $\\pi_t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class pois_dglm(dglm):\n",
    "\n",
    "    def get_conjugate_params(self, ft, qt, alpha_init, beta_init):\n",
    "        # Choose conjugate prior, gamma, and match mean & variance\n",
    "        return pois_conjugate_params(ft, qt, alpha_init, beta_init, interp=self.interpolate)\n",
    "\n",
    "    def update_conjugate_params(self, y, alpha, beta):\n",
    "        # Update alpha and beta to the conjugate posterior coefficients\n",
    "        alpha = alpha + float(y)\n",
    "        beta = beta + 1\n",
    "\n",
    "        # Get updated ft* and qt*\n",
    "        ft_star = digamma(alpha) - np.log(beta)\n",
    "        qt_star = trigamma(alpha)\n",
    "\n",
    "        # constrain this thing from going to crazy places?\n",
    "        qt_star = max(0.001 ** 2, min(qt_star, 4 ** 2))\n",
    "\n",
    "        return alpha, beta, ft_star, qt_star\n",
    "\n",
    "    def simulate(self, alpha, beta, nsamps):\n",
    "        return np.random.negative_binomial(alpha, beta / (1 + beta), [nsamps])\n",
    "\n",
    "    def simulate_from_sampling_model(self, rate, nsamps):\n",
    "        return np.random.poisson(rate, [nsamps])\n",
    "\n",
    "    def simulate_from_prior(self, alpha, beta, nsamps):\n",
    "        return stats.gamma.rvs(a=alpha, scale=1/beta, size=nsamps)\n",
    "\n",
    "    def prior_inverse_cdf(self, cdf, alpha, beta):\n",
    "        return stats.gamma.ppf(cdf, a=alpha, scale=1 / beta)\n",
    "\n",
    "    def sampling_density(self, y, mu):\n",
    "        return stats.poisson.pmf(mu=mu, k=y)\n",
    "\n",
    "    def marginal_cdf(self, y, alpha, beta):\n",
    "        return stats.nbinom.cdf(y, alpha, beta / (1 + beta))\n",
    "\n",
    "    def marginal_inverse_cdf(self, cdf, alpha, beta):\n",
    "        return stats.nbinom.ppf(cdf, alpha, beta / (1 + beta))\n",
    "\n",
    "    def loglik(self, y, alpha, beta):\n",
    "        return stats.nbinom.logpmf(y, alpha, beta / (1 + beta))\n",
    "\n",
    "    def get_mean(self, alpha, beta):\n",
    "        return np.ravel(alpha/beta)[0]\n",
    "\n",
    "    def get_prior_var(self, alpha, beta):\n",
    "        return alpha / beta ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Poisson DGLM models non-negative integers:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "y_t &\\sim Pois(\\mu_t) \\\\\n",
    "\\mu_t &= e^{\\lambda_t} \\\\\n",
    "\\lambda_{t} &= F_{t}' \\theta_{t}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Where\n",
    "- Pois($\\mu_t$) is the [Poisson distribution](https://en.wikipedia.org/wiki/Poisson_distribution) with rate parameter $\\mu_t$\n",
    "- $\\mu_t$ is exponent of $\\lambda_t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class dlm(dglm):\n",
    "\n",
    "    def __init__(self, *args, n0=1, s0=1, delVar=1, **kwargs):\n",
    "        self.delVar = delVar  # Discount factor for the variance - using a beta-gamma random walk\n",
    "        self.n = n0  # Prior sample size for the variance\n",
    "        self.s = s0  # Prior mean for the variance\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def get_mean_and_var(self, F, a, R):\n",
    "        return F.T @ a, F.T @ R @ F + self.s\n",
    "\n",
    "    def get_mean_and_var_lf(self, F, a, R, phi_mu, phi_sigma, ilf):\n",
    "        ct = self.n / (self.n - 2)\n",
    "        ft, qt = get_mean_and_var_lf_dlm(F, a, R, phi_mu, phi_sigma, ilf, ct)\n",
    "        qt = qt + self.s\n",
    "        return ft, qt\n",
    "\n",
    "    def get_mean(self, ft, qt):\n",
    "        return np.ravel(ft)[0]\n",
    "\n",
    "    def get_conjugate_params(self, ft, qt, mean, var):\n",
    "        return ft, qt\n",
    "\n",
    "    def simulate(self, mean, var, nsamps):\n",
    "        return mean + np.sqrt(var) * np.random.standard_t(self.n, size=[nsamps])\n",
    "\n",
    "    def simulate_from_sampling_model(self, mean, var, nsamps):\n",
    "        return np.random.normal(mean, np.sqrt(var), nsamps)\n",
    "\n",
    "    def update(self, y=None, X=None, phi_mu=None, phi_sigma=None, analytic=True, phi_samps=None, **kwargs):\n",
    "        if self.latent_factor:\n",
    "            if analytic:\n",
    "                update_lf_analytic_dlm(self, y, X, phi_mu, phi_sigma)\n",
    "            else:\n",
    "                print('Sampled-based updating for the Latent Factor DLM is not yet implemented - please use analytic inference')\n",
    "        else:\n",
    "            update_dlm(self, y, X)\n",
    "\n",
    "    def forecast_path(self, k, X=None, nsamps=1, **kwargs):\n",
    "        if self.latent_factor:\n",
    "            print('Path forecasting for latent factor DLMs is not yet implemented')\n",
    "        else:\n",
    "            return forecast_path_dlm(self, k, X, nsamps)\n",
    "\n",
    "    def update_lf_analytic(self, y=None, X=None, phi_mu=None, phi_sigma=None):\n",
    "        update_lf_analytic_dlm(self, y, X, phi_mu, phi_sigma)\n",
    "\n",
    "    def loglik(self, y, mean, var):\n",
    "        return stats.t.logpdf(y, df=self.n, loc=mean, scale=np.sqrt(var))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A normal DLM has a slightly different form than other DGLMs:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "y_t &= \\mu_t + \\epsilon_t \\\\\n",
    "\\mu_t &= \\lambda_{t} = F_{t}' \\theta_{t} \\\\\n",
    "\\epsilon_t &\\sim N(0, \\sigma^2_t)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Where\n",
    "- N($0, \\sigma^2_t$) is the [Normal distribution](https://en.wikipedia.org/wiki/normal_distribution) with mean $0$ and variance $\\sigma^2_t$\n",
    "- $\\sigma^2_t$ is also a dynamic parameter, with its own evolution through time. The discount factor `mod.delVar` is set by the modeler, and controls the rate at which $\\sigma^2$ changes. Typically it is set between $0.95-1$. The mean of $\\sigma_t^2$ is stored as `mod.s`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class bin_dglm(dglm):\n",
    "\n",
    "    def get_conjugate_params(self, ft, qt, alpha_init, beta_init):\n",
    "        # Choose conjugate prior, beta, and match mean & variance\n",
    "        return bin_conjugate_params(ft, qt, alpha_init, beta_init, interp=self.interpolate)\n",
    "\n",
    "    def update_conjugate_params(self, n, y, alpha, beta):\n",
    "        # Update alpha and beta to the conjugate posterior coefficients\n",
    "        alpha = alpha + y\n",
    "        beta = beta + n - y\n",
    "\n",
    "        # Get updated ft* and qt*\n",
    "        ft_star = digamma(alpha) - digamma(beta)\n",
    "        qt_star = trigamma(alpha) + trigamma(beta)\n",
    "\n",
    "        # constrain this thing from going to crazy places?\n",
    "        ft_star = max(-8, min(ft_star, 8))\n",
    "        qt_star = max(0.001 ** 2, min(qt_star, 4 ** 2))\n",
    "\n",
    "        return alpha, beta, ft_star, qt_star\n",
    "\n",
    "    def simulate(self, n, alpha, beta, nsamps):\n",
    "        p = np.random.beta(alpha, beta, [nsamps])\n",
    "        return np.random.binomial(n.astype(int), p, size=[nsamps])\n",
    "\n",
    "    def simulate_from_sampling_model(self, n, p, nsamps):\n",
    "        return np.random.binomial(n, p, [nsamps])\n",
    "\n",
    "    def prior_inverse_cdf(self, cdf, alpha, beta):\n",
    "        return stats.beta.ppf(cdf, alpha, beta)\n",
    "\n",
    "    def marginal_cdf(self, y, n, alpha, beta):\n",
    "        cdf = 0.0\n",
    "        for i in range(y + 1):\n",
    "            cdf += sc.misc.comb(n, y) * beta_fxn(y + alpha, n - y + beta) / beta_fxn(alpha, beta)\n",
    "        return cdf\n",
    "\n",
    "    def loglik(self, data, alpha, beta):\n",
    "        n, y = data\n",
    "        return stats.binom.logpmf(y, n, alpha / (alpha + beta))\n",
    "\n",
    "    def get_mean(self, n, alpha, beta):\n",
    "        return np.ravel(n * (alpha / (alpha + beta)))[0]\n",
    "\n",
    "    def get_prior_var(self, alpha, beta):\n",
    "        return (alpha * beta) / ((alpha + beta) ** 2 * (alpha + beta + 1))\n",
    "\n",
    "    def update(self, n=None, y=None, X=None):\n",
    "        update_bindglm(self, n, y, X)\n",
    "\n",
    "    def forecast_marginal(self, n, k, X=None, nsamps=1, mean_only=False):\n",
    "        return forecast_marginal_bindglm(self, n, k, X, nsamps, mean_only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Binomial DGLM models the sum of independent $0-1$ observations:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "y_t &\\sim Bin(n_t, pi_t) \\\\\n",
    "\\pi_t &= 1/(1 + e^{-\\lambda_t}) \\\\\n",
    "\\lambda_{t} &= F_{t}' \\theta_{t}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Where\n",
    "- Bin($n_t, pi_t$) is the [Binomial distribution](https://en.wikipedia.org/wiki/Binomial_distribution) with $n_t$ independent trials, each having probability $\\pi_t$\n",
    "- $\\lambda_t$ is transformed through the [logistic function](https://en.wikipedia.org/wiki/Logistic_function) to become $\\pi_t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_dglm.ipynb.\n",
      "Converted 01_update.ipynb.\n",
      "Converted 02_forecast.ipynb.\n",
      "Converted 03_define_models.ipynb.\n",
      "Converted 04_seasonal.ipynb.\n",
      "Converted 05_analysis.ipynb.\n",
      "Converted 06_conjugates.ipynb.\n",
      "Converted 07_point_forecast.ipynb.\n",
      "Converted 08_loss_functions.ipynb.\n",
      "Converted 09_plot.ipynb.\n",
      "Converted 10_shared.ipynb.\n",
      "Converted 11_dcmm.ipynb.\n",
      "Converted 12_dbcm.ipynb.\n",
      "Converted 13_latent_factor.ipynb.\n",
      "Converted 14_latent_factor_fxns.ipynb.\n",
      "Converted 15_dlmm.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
