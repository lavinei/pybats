{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update\n",
    "\n",
    "> This module contains the update algorithm for a DGLM. After observing a new value $y_t$, updating incorporates the new information into the DGLM coefficients. It also applies the discount factors to reduce the impact of older information. For any model `mod`, the correct method usage is `mod.update(y, X)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Updating occurs after observing a new value, $y_t$. The update function accepts $y_t$ and the predictors $X_t$.  It will update the state vector from $\\theta_t$ into $\\theta_{t+1}$, producing the new mean $a_{t+1}$ and variance matrix $R_{t+1}$. In a normal DLM, the updating also impacts the mean of the observation variance, $s_{t+1}$. The coefficients can be accessed with `mod.get_coef`, or more directly as `mod.a`, `mod.R`, and for a normal DLM, `mod.s`.\n",
    "\n",
    "To give the more formal Bayesian interpretation of these steps: \n",
    "- At time $t$, we know the prior moments of the state vector $\\theta_t | \\mathcal{D_t} \\sim [a_t, R_t]$, where $\\mathcal{D_t}$ is all of the observations up to time $t$. \n",
    "- We then observe $y_t$, and incorporate the new information to give the posterior: $\\theta_t | \\mathcal{D_t}, y_t \\sim [m_t, C_t]$. \n",
    "- Finally, we discount the old information, to give us our new priors for the next time step: $\\theta_{t+1} | \\mathcal{D_{t+1}} \\sim [a_{t+1}, R_{t+1}]$.\n",
    "\n",
    "\n",
    "If you are interested in the posterior moments of $\\theta_t | \\mathcal{D_t}, y_t$ before the discounting is applied, then you can access `mod.m` and `mod.C`, although these are rarely used.\n",
    "\n",
    "Again, these functions do not need to be accessed independently from a model. Every model in PyBATS has a `mod.update(y, X)` method, which will call the appropriate update function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "def update_F(mod, X, F=None):\n",
    "    if F is None:\n",
    "        if mod.nregn > 0:\n",
    "            mod.F[mod.iregn] = X.reshape(mod.nregn, 1)\n",
    "    else:\n",
    "        if mod.nregn > 0:\n",
    "            # F = mod.F.copy()\n",
    "            F[mod.iregn] = X.reshape(mod.nregn, 1)\n",
    "        return F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def update(mod, y = None, X = None):\n",
    "\n",
    "    # If data is missing then skip discounting and updating, posterior = prior\n",
    "    if y is None or np.isnan(y):\n",
    "        mod.t += 1\n",
    "        mod.m = mod.a\n",
    "        mod.C = mod.R\n",
    "\n",
    "        # Get priors a, R for time t + 1 from the posteriors m, C\n",
    "        mod.a = mod.G @ mod.m\n",
    "        mod.R = mod.G @ mod.C @ mod.G.T\n",
    "        mod.R = (mod.R + mod.R.T)/2\n",
    "\n",
    "        mod.W = mod.get_W(X=X)\n",
    "\n",
    "    else:\n",
    "\n",
    "        update_F(mod, X)\n",
    "\n",
    "        # Mean and variance\n",
    "        ft, qt = mod.get_mean_and_var(mod.F, mod.a, mod.R)\n",
    "\n",
    "        # Choose conjugate prior, match mean and variance (variational Bayes step)\n",
    "        mod.param1, mod.param2 = mod.get_conjugate_params(ft, qt, mod.param1, mod.param2)\n",
    "\n",
    "        # See time t observation y (which was passed into the update function)\n",
    "        mod.t += 1\n",
    "\n",
    "        # Update the conjugate parameters and get the implied ft* and qt*\n",
    "        mod.param1, mod.param2, ft_star, qt_star = mod.update_conjugate_params(y, mod.param1, mod.param2)\n",
    "\n",
    "        # Filter update on the state vector (using Linear Bayes approximation)\n",
    "        mod.m = mod.a + mod.R @ mod.F * (ft_star - ft)/qt\n",
    "        mod.C = mod.R - mod.R @ mod.F @ mod.F.T @ mod.R * (1 - qt_star/qt)/qt\n",
    "\n",
    "        # Get priors a, R for time t + 1 from the posteriors m, C\n",
    "        mod.a = mod.G @ mod.m\n",
    "        mod.R = mod.G @ mod.C @ mod.G.T\n",
    "        mod.R = (mod.R + mod.R.T)/2\n",
    "\n",
    "        # Discount information in the time t + 1 prior\n",
    "        mod.W = mod.get_W(X=X)\n",
    "        mod.R = mod.R + mod.W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This update method works for Poisson and Bernoulli DGLMs. Below are very simple tests which:\n",
    "- Manually define a DGLM with an intercept and 2 regression predictors\n",
    "- Define a new $y_t, X_t$\n",
    "- Update the model, given $y_t, X_t$\n",
    "- Check that the posterior mean $a_t$ and variance $R_t$ of the state vector is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pybats.dglm import dlm, pois_dglm, bern_dglm, bin_dglm\n",
    "from pybats.analysis import analysis\n",
    "\n",
    "a0 = np.array([1, 1, 1])\n",
    "R0 = np.eye(3)\n",
    "mod_p = pois_dglm(a0, R0, ntrend=1, nregn=2, deltrend=1, delregn=.9)\n",
    "mod_bern = bern_dglm(a0, R0, ntrend=1, nregn=2, deltrend=1, delregn=.9)\n",
    "\n",
    "# New data:\n",
    "y = 5\n",
    "X = np.array([1,2])\n",
    "\n",
    "# Test the Poisson DGLM\n",
    "mod_p.update(y=y, X=X)\n",
    "ans = np.array([[0.59974735],\n",
    "   [0.59974735],\n",
    "   [0.1994947 ]])\n",
    "assert (np.equal(np.round(ans, 5), np.round(mod_p.a, 5)).all())\n",
    "\n",
    "ans = np.array([-0.16107008, 0.93214436])\n",
    "assert (np.equal(np.round(ans, 5), np.round(mod_p.R[0:2, 1], 5)).all())\n",
    "\n",
    "# Test the Bernoulli DGLM\n",
    "mod_bern.update(y=1, X=X)\n",
    "ans = np.array([[1.02626224],\n",
    "                [1.02626224],\n",
    "                [1.05252447]])\n",
    "assert (np.equal(np.round(ans, 5), np.round(mod_bern.a, 5)).all())\n",
    "\n",
    "ans = np.array([-1.00331466e-04,  1.11099963])\n",
    "assert (np.equal(np.round(ans, 5), np.round(mod_bern.R[0:2, 1], 5)).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def update_dlm(mod, y = None, X = None):\n",
    "\n",
    "    # If data is missing then skip discounting and updating, posterior = prior\n",
    "    if y is None or np.isnan(y):\n",
    "        mod.t += 1\n",
    "        mod.m = mod.a\n",
    "        mod.C = mod.R\n",
    "\n",
    "        # Get priors a, R for time t + 1 from the posteriors m, C\n",
    "        mod.a = mod.G @ mod.m\n",
    "        mod.R = mod.G @ mod.C @ mod.G.T\n",
    "        mod.R = (mod.R + mod.R.T)/2\n",
    "\n",
    "        mod.W = mod.get_W(X=X)\n",
    "\n",
    "    else:\n",
    "        update_F(mod, X)\n",
    "\n",
    "        # Mean and variance\n",
    "        ft, qt = mod.get_mean_and_var(mod.F, mod.a, mod.R)\n",
    "        mod.param1 = ft\n",
    "        mod.param2 = qt\n",
    "\n",
    "        # See time t observation y (which was passed into the update function)\n",
    "        mod.t += 1\n",
    "\n",
    "        # Update the  parameters:\n",
    "        et = y - ft\n",
    "\n",
    "        # Adaptive coefficient vector\n",
    "        At = mod.R @ mod.F / qt\n",
    "\n",
    "        # Volatility estimate ratio\n",
    "        rt = (mod.n + et**2/qt)/(mod.n + 1)\n",
    "\n",
    "        # Kalman filter update\n",
    "        mod.n = mod.n + 1\n",
    "        mod.s = mod.s * rt\n",
    "        mod.m = mod.a + At * et\n",
    "        mod.C = rt * (mod.R - qt * At @ At.T)\n",
    "\n",
    "        # Get priors a, R for time t + 1 from the posteriors m, C\n",
    "        mod.a = mod.G @ mod.m\n",
    "        mod.R = mod.G @ mod.C @ mod.G.T\n",
    "        mod.R = (mod.R + mod.R.T)/2\n",
    "\n",
    "        # Discount information\n",
    "        mod.W = mod.get_W(X=X)\n",
    "        mod.R = mod.R + mod.W\n",
    "        mod.n = mod.delVar * mod.n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This update method works for normal DLMs. Here is a similar updating test, calling the method as `mod_n.update`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_n = dlm(a0, R0, ntrend=1, nregn=2, deltrend=1, delregn=.9)\n",
    "\n",
    "# Test the normal DLM\n",
    "mod_n.update(y = y, X=X)\n",
    "ans = np.array([[1.14285714],\n",
    "   [1.14285714],\n",
    "   [1.28571429]])\n",
    "assert(np.equal(np.round(ans, 5), np.round(mod_n.a, 5)).all())\n",
    "\n",
    "ans = np.array([-0.08163265, 0.54421769])\n",
    "assert(np.equal(np.round(ans, 5), np.round(mod_n.R[0:2,1], 5)).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def update_bindglm(mod, n=None, y=None, X=None):\n",
    "\n",
    "    # If data is missing then skip discounting and updating, posterior = prior\n",
    "    if y is None or np.isnan(y) or n is None or np.isnan(n) or n == 0:\n",
    "        mod.t += 1\n",
    "        mod.m = mod.a\n",
    "        mod.C = mod.R\n",
    "\n",
    "        # Get priors a, R for time t + 1 from the posteriors m, C\n",
    "        mod.a = mod.G @ mod.m\n",
    "        mod.R = mod.G @ mod.C @ mod.G.T\n",
    "        mod.R = (mod.R + mod.R.T) / 2\n",
    "\n",
    "        mod.W = mod.get_W(X=X)\n",
    "\n",
    "    else:\n",
    "\n",
    "        update_F(mod, X)\n",
    "\n",
    "        # Mean and variance\n",
    "        ft, qt = mod.get_mean_and_var(mod.F, mod.a, mod.R)\n",
    "\n",
    "        # Choose conjugate prior, match mean and variance\n",
    "        mod.param1, mod.param2 = mod.get_conjugate_params(ft, qt, mod.param1, mod.param2)\n",
    "\n",
    "        # See time t observation y (which was passed into the update function)\n",
    "        mod.t += 1\n",
    "\n",
    "        # Update the conjugate parameters and get the implied ft* and qt*\n",
    "        mod.param1, mod.param2, ft_star, qt_star = mod.update_conjugate_params(n, y, mod.param1, mod.param2)\n",
    "\n",
    "        # Kalman filter update on the state vector (using Linear Bayes approximation)\n",
    "        mod.m = mod.a + mod.R @ mod.F * (ft_star - ft) / qt\n",
    "        mod.C = mod.R - mod.R @ mod.F @ mod.F.T @ mod.R * (1 - qt_star / qt) / qt\n",
    "\n",
    "        # Get priors a, R for time t + 1 from the posteriors m, C\n",
    "        mod.a = mod.G @ mod.m\n",
    "        mod.R = mod.G @ mod.C @ mod.G.T\n",
    "        mod.R = (mod.R + mod.R.T) / 2\n",
    "\n",
    "        # Discount information in the time t + 1 prior\n",
    "        mod.W = mod.get_W(X=X)\n",
    "        mod.R = mod.R + mod.W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This update method works for binomial DGLMs. Here is a similar updating test, calling the method as `mod_b.update`. Note that for a binomial DGLM, we must specify the number of trials, $n_t$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_b = bin_dglm(a0, R0, ntrend=1, nregn=2, deltrend=1, delregn=.9)\n",
    "\n",
    "# New data - the number of trials\n",
    "n = 10\n",
    "\n",
    "# Test the Binomial DGLM\n",
    "mod_b.update(y=y, X=X, n=n)\n",
    "ans = np.array([[ 0.46543905],\n",
    "   [ 0.46543905],\n",
    "   [-0.0691219 ]])\n",
    "assert (np.equal(np.round(ans, 5), np.round(mod_b.a, 5)).all())\n",
    "\n",
    "ans = np.array([-0.15854342, 0.93495175])\n",
    "assert (np.equal(np.round(ans, 5), np.round(mod_b.R[0:2, 1], 5)).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_dglm.ipynb.\n",
      "Converted 01_update.ipynb.\n",
      "Converted 02_forecast.ipynb.\n",
      "Converted 03_define_models.ipynb.\n",
      "Converted 04_seasonal.ipynb.\n",
      "Converted 05_analysis.ipynb.\n",
      "Converted 06_conjugates.ipynb.\n",
      "Converted 07_point_forecast.ipynb.\n",
      "Converted 08_loss_functions.ipynb.\n",
      "Converted 09_plot.ipynb.\n",
      "Converted 10_shared.ipynb.\n",
      "Converted 11_dcmm.ipynb.\n",
      "Converted 12_dbcm.ipynb.\n",
      "Converted 13_latent_factor.ipynb.\n",
      "Converted 14_latent_factor_fxns.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
