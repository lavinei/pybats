{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp dcmm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCMM\n",
    "\n",
    "> A Dynamic Count Mixture Model, or DCMM, is the combination of a Bernoulli and Poisson DGLM as described in [Berry and West (2019)](https://arxiv.org/pdf/1805.05232.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DCMM is a combination of a Bernoulli and Poisson DGLM. The Bernoulli DGLM models the probability of the observation being zero. Conditional on a non-zero outcome, then the observation follows a Poisson distribution. This is useful for modeling time series with a greater number of zeros than expected under a Poisson distribution, which is frequently the case for low-valued count time series.\n",
    "\n",
    "In more formal terms, a DCMM models observations $y_t$ as:\n",
    "$$\n",
    "\\quad z_{t} \\sim Bern(\\pi_{t}) \\quad \\textrm{and}\\quad y_{t} | z_{t}  = \n",
    "\\begin{cases}\n",
    "0, & \\text{if } z_{t} = 0,\\\\\n",
    "1 + x_{t}, \\quad x_{t} \\sim Pois(\\mu_{t}), & \\textrm{if}\\ z_{t} = 1.\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#exporti\n",
    "import numpy as np\n",
    "from pybats.latent_factor_fxns import forecast_marginal_lf_dcmm, forecast_path_lf_dcmm\n",
    "from pybats.dglm import bern_dglm, pois_dglm\n",
    "from pybats.update import update_F\n",
    "from scipy.special import expit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class dcmm:\n",
    "    def __init__(self,\n",
    "                 a0_bern = None,\n",
    "                 R0_bern = None,\n",
    "                 nregn_bern = 0,\n",
    "                 ntrend_bern = 0,\n",
    "                 nlf_bern = 0,\n",
    "                 nhol_bern = 0,\n",
    "                 seasPeriods_bern = [],\n",
    "                 seasHarmComponents_bern = [],\n",
    "                 deltrend_bern = 1, delregn_bern = 1,\n",
    "                 delhol_bern = 1,\n",
    "                 delseas_bern = 1, dellf_bern = 1,\n",
    "                 a0_pois = None,\n",
    "                 R0_pois = None,\n",
    "                 nregn_pois = 0,\n",
    "                 ntrend_pois = 0,\n",
    "                 nlf_pois = 0,\n",
    "                 nhol_pois = 0,\n",
    "                 seasPeriods_pois = [],\n",
    "                 seasHarmComponents_pois = [],\n",
    "                 deltrend_pois = 1, delregn_pois = 1,\n",
    "                 delhol_pois = 1,\n",
    "                 delseas_pois = 1, dellf_pois = 1,\n",
    "                 rho = 1,\n",
    "                 interpolate=True,\n",
    "                 adapt_discount=False):\n",
    "        \"\"\"\n",
    "        :param a0_bern: Prior mean vector for bernoulli DGLM\n",
    "        :param R0_bern: Prior covariance matrix for bernoulli DGLM\n",
    "        :param nregn_bern: Number of regression components in bernoulli DGLM\n",
    "        :param ntrend_bern: Number of trend components in bernoulli DGLM\n",
    "        :param nlf_bern: Number of latent factor components in bernoulli DGLM\n",
    "        :param seasPeriods_bern: List of periods of seasonal components in bernoulli DGLM\n",
    "        :param seasHarmComponents_bern: List of harmonic components included for each period in bernoulli DGLM\n",
    "        :param deltrend_bern: Discount factor on trend components in bernoulli DGLM\n",
    "        :param delregn_bern: Discount factor on regression components in bernoulli DGLM\n",
    "        :param delhol_bern: Discount factor on holiday component in bernoulli DGLM (currently deprecated)\n",
    "        :param delseas_bern: Discount factor on seasonal components in bernoulli DGLM\n",
    "        :param dellf_bern: Discount factor on latent factor components in bernoulli DGLM\n",
    "        :param a0_pois: Prior mean vector for poisson DGLM\n",
    "        :param R0_pois: Prior covariance matrix for poisson DGLM\n",
    "        :param nregn_pois: Number of regression components in poisson DGLM\n",
    "        :param ntrend_pois: Number of trend components in poisson DGLM\n",
    "        :param nlf_pois: Number of latent factor components in poisson DGLM\n",
    "        :param seasPeriods_pois: List of periods of seasonal components in poisson DGLM\n",
    "        :param seasHarmComponents_pois: List of harmonic components included for each period in poisson DGLM\n",
    "        :param deltrend_pois: Discount factor on trend components in poisson DGLM\n",
    "        :param delregn_pois: Discount factor on regression components in poisson DGLM\n",
    "        :param delhol_pois: Discount factor on holiday component in poisson DGLM (currently deprecated)\n",
    "        :param delseas_pois: Discount factor on seasonal components in poisson DGLM\n",
    "        :param dellf_pois: Discount factor on latent factor components in poisson DGLM\n",
    "        :param rho: Discount factor for random effects extension in poisson DGLM (smaller rho increases variance)\n",
    "        \"\"\"\n",
    "\n",
    "        self.bern_mod = bern_dglm(a0=a0_bern,\n",
    "                                  R0=R0_bern,\n",
    "                                  nregn=nregn_bern,\n",
    "                                  ntrend=ntrend_bern,\n",
    "                                  nlf=nlf_bern,\n",
    "                                  nhol=nhol_bern,\n",
    "                                  seasPeriods=seasPeriods_bern,\n",
    "                                  seasHarmComponents=seasHarmComponents_bern,\n",
    "                                  deltrend=deltrend_bern, delregn=delregn_bern,\n",
    "                                  delhol=delhol_bern, delseas=delseas_bern,\n",
    "                                  dellf=dellf_bern,\n",
    "                                  interpolate=interpolate,\n",
    "                                  adapt_discount=adapt_discount)\n",
    "\n",
    "        self.pois_mod = pois_dglm(a0=a0_pois,\n",
    "                                  R0=R0_pois,\n",
    "                                  nregn=nregn_pois,\n",
    "                                  ntrend=ntrend_pois,\n",
    "                                  nlf=nlf_pois,\n",
    "                                  nhol=nhol_pois,\n",
    "                                  seasPeriods=seasPeriods_pois,\n",
    "                                  seasHarmComponents=seasHarmComponents_pois,\n",
    "                                  deltrend=deltrend_pois, delregn=delregn_pois,\n",
    "                                  delhol=delhol_pois, delseas=delseas_pois,\n",
    "                                  dellf=dellf_pois,\n",
    "                                  rho=rho,\n",
    "                                  interpolate=interpolate,\n",
    "                                  adapt_discount=adapt_discount)\n",
    "\n",
    "        self.t = 0\n",
    "\n",
    "\n",
    "    # X is a list or tuple of length 2. The first component is data for the bernoulli DGLM, the next is for the Poisson DGLM.\n",
    "    def update(self, y = None, X = None):\n",
    "        X = self.make_pair(X)\n",
    "\n",
    "        if y is None:\n",
    "            self.bern_mod.update(y=y)\n",
    "            self.pois_mod.update(y=y)\n",
    "        elif y == 0:\n",
    "            self.bern_mod.update(y = 0, X = X[0])\n",
    "            self.pois_mod.update(y = np.nan, X = X[1])\n",
    "        else: # only update beta model if we have significant uncertainty in the forecast\n",
    "            # get the lower end forecast on the logit scale\n",
    "            F = update_F(self.bern_mod, X[0], F=self.bern_mod.F.copy())\n",
    "            ft, qt = self.bern_mod.get_mean_and_var(F, self.bern_mod.a, self.bern_mod.R)\n",
    "            fcast_logit_lb = ft - np.sqrt(qt)\n",
    "            # translate to a prod for a rough idea of whether we're already pretty confident for this forecast\n",
    "            if expit(fcast_logit_lb) < 0.975:\n",
    "                self.bern_mod.update(y=1, X = X[0])\n",
    "            else:\n",
    "                self.bern_mod.update(y=np.nan, X=X[0])\n",
    "            self.pois_mod.update(y = y - 1, X = X[1]) # Shifted Y values in the Poisson DGLM\n",
    "\n",
    "        self.t += 1\n",
    "\n",
    "    def update_lf_sample(self, y = None, X = None, phi_samps = None, parallel=False):\n",
    "        X = self.make_pair(X)\n",
    "        phi_samps = self.make_pair(phi_samps)\n",
    "\n",
    "        if y is None:\n",
    "            self.bern_mod.update_lf_sample(y=y)\n",
    "            self.pois_mod.update_lf_sample(y=y)\n",
    "        elif y == 0:\n",
    "            self.bern_mod.update_lf_sample(y = 0, X = X[0], phi_samps = phi_samps[0], parallel = parallel)\n",
    "            self.pois_mod.update_lf_sample(y = np.nan, X = X[1], phi_samps = phi_samps[1], parallel = parallel)\n",
    "        else:\n",
    "            self.bern_mod.update_lf_sample(y = 1, X = X[0], phi_samps = phi_samps[0], parallel = parallel)\n",
    "            # Shifted Y values in the Poisson DGLM\n",
    "            self.pois_mod.update_lf_sample(y =y - 1, X = X[1], phi_samps = phi_samps[1], parallel = parallel)\n",
    "\n",
    "        self.t += 1\n",
    "\n",
    "    def update_lf_analytic(self, y = None, X = None, phi_mu = None, phi_sigma = None):\n",
    "        X = self.make_pair(X)\n",
    "        phi_mu = self.make_pair(phi_mu)\n",
    "        phi_sigma = self.make_pair(phi_sigma)\n",
    "\n",
    "        if y is None:\n",
    "            self.bern_mod.update_lf_analytic(y=y)\n",
    "            self.pois_mod.update_lf_analytic(y=y)\n",
    "        elif y == 0:\n",
    "            self.bern_mod.update_lf_analytic(y = 0, X = X[0], phi_mu = phi_mu[0], phi_sigma = phi_sigma[0])\n",
    "            self.pois_mod.update_lf_analytic(y = np.nan, X = X[1], phi_mu = phi_mu[1], phi_sigma = phi_sigma[1])\n",
    "        else:\n",
    "            self.bern_mod.update_lf_analytic(y = 1, X = X[0], phi_mu = phi_mu[0], phi_sigma = phi_sigma[0])\n",
    "            # Shifted Y values in the Poisson DGLM\n",
    "            self.pois_mod.update_lf_analytic(y =y - 1, X = X[1], phi_mu = phi_mu[1], phi_sigma = phi_sigma[1])\n",
    "\n",
    "        self.t += 1\n",
    "\n",
    "    def forecast_marginal(self, k, X = None, nsamps = 1, mean_only = False, state_mean_var = False):\n",
    "        X = self.make_pair(X)\n",
    "\n",
    "        if mean_only:\n",
    "            mean_bern = self.bern_mod.forecast_marginal(k, X[0], nsamps, mean_only)\n",
    "            mean_pois = self.pois_mod.forecast_marginal(k, X[1], nsamps, mean_only)\n",
    "            return mean_bern * (mean_pois + 1)\n",
    "        elif state_mean_var:\n",
    "            mv_bern = self.bern_mod.forecast_marginal(k, X[0], state_mean_var = state_mean_var)\n",
    "            mv_pois = self.pois_mod.forecast_marginal(k, X[1], state_mean_var = state_mean_var)\n",
    "            return mv_bern, mv_pois\n",
    "        else:\n",
    "            samps_bern = self.bern_mod.forecast_marginal(k, X[0], nsamps)\n",
    "            samps_pois = self.pois_mod.forecast_marginal(k, X[1], nsamps) + np.ones([nsamps]) # Shifted Y values in the Poisson DGLM\n",
    "            return samps_bern * samps_pois\n",
    "\n",
    "    def forecast_marginal_lf_analytic(self, k, X = None, phi_mu = None, phi_sigma = None, nsamps = 1, mean_only = False, state_mean_var = False):\n",
    "        X = self.make_pair(X)\n",
    "        phi_mu = self.make_pair(phi_mu)\n",
    "        phi_sigma = self.make_pair(phi_sigma)\n",
    "\n",
    "        if mean_only:\n",
    "            mean_bern = self.bern_mod.forecast_marginal_lf_analytic(k, X[0], phi_mu[0], phi_sigma[0], nsamps, mean_only)\n",
    "            mean_pois = self.pois_mod.forecast_marginal_lf_analytic(k, X[1], phi_mu[1], phi_sigma[1], nsamps, mean_only)\n",
    "            return np.array([[mean_bern * (mean_pois + 1)]])\n",
    "        elif state_mean_var:\n",
    "            mv_bern = self.bern_mod.forecast_marginal_lf_analytic(k, X[0], phi_mu[0], phi_sigma[0], state_mean_var = state_mean_var)\n",
    "            mv_pois = self.pois_mod.forecast_marginal_lf_analytic(k, X[1], phi_mu[1], phi_sigma[1], state_mean_var = state_mean_var)\n",
    "            return mv_bern, mv_pois\n",
    "        else:\n",
    "            samps_bern = self.bern_mod.forecast_marginal_lf_analytic(k, X[0], phi_mu = phi_mu[0], phi_sigma = phi_sigma[0], nsamps = nsamps)\n",
    "            samps_pois = self.pois_mod.forecast_marginal_lf_analytic(k, X[1], phi_mu = phi_mu[1], phi_sigma = phi_sigma[1], nsamps = nsamps) + np.ones([nsamps]) # Shifted Y values in the Poisson DGLM\n",
    "            return samps_bern * samps_pois\n",
    "\n",
    "    def forecast_marginal_lf_analytic_new(self, k, X = None, phi_mu = None, phi_sigma = None, nsamps = 1, mean_only = False, state_mean_var = False):\n",
    "        X = self.make_pair(X)\n",
    "        phi_mu = self.make_pair(phi_mu)\n",
    "        phi_sigma = self.make_pair(phi_sigma)\n",
    "\n",
    "        if mean_only:\n",
    "            mean_bern = self.bern_mod.forecast_marginal_lf_analytic(k, X[0], phi_mu[0], phi_sigma[0], nsamps, mean_only)\n",
    "            mean_pois = self.pois_mod.forecast_marginal_lf_analytic(k, X[1], phi_mu[1], phi_sigma[1], nsamps, mean_only)\n",
    "            return np.array([[mean_bern * (mean_pois + 1)]])\n",
    "        elif state_mean_var:\n",
    "            mv_bern = self.bern_mod.forecast_marginal_lf_analytic(k, X[0], phi_mu[0], phi_sigma[0], state_mean_var = state_mean_var)\n",
    "            mv_pois = self.pois_mod.forecast_marginal_lf_analytic(k, X[1], phi_mu[1], phi_sigma[1], state_mean_var = state_mean_var)\n",
    "            return mv_bern, mv_pois\n",
    "        else:\n",
    "            return forecast_marginal_lf_dcmm(self, k, X[0], phi_mu[0], phi_sigma[0], nsamps=nsamps)\n",
    "\n",
    "    def forecast_marginal_lf_sample(self, k, X = None, phi_samps = None, nsamps = 1, mean_only = False):\n",
    "        X = self.make_pair(X)\n",
    "        phi_samps = self.make_pair(phi_samps)\n",
    "\n",
    "        samps_bern = self.bern_mod.forecast_marginal_lf_sample(k, X[0], phi_samps[0], mean_only)\n",
    "        samps_pois = self.pois_mod.forecast_marginal_lf_sample(k, X[1], phi_samps[1], mean_only) + np.ones([nsamps]) # Shifted Y values in the Poisson DGLM\n",
    "        return samps_bern * samps_pois\n",
    "\n",
    "    def forecast_path_lf_sample(self, k, X = None, phi_samps=None, nsamps = 1):\n",
    "        X = self.make_pair(X)\n",
    "        phi_samps = self.make_pair(phi_samps)\n",
    "\n",
    "        samps_bern = self.bern_mod.forecast_path_lf_sample(k, X[0], phi_samps[0], nsamps)\n",
    "        samps_pois = self.pois_mod.forecast_path_lf_sample(k, X[1], phi_samps[1], nsamps) + np.ones([nsamps, k]) # Shifted Y values in the Poisson DGLM\n",
    "        return samps_bern * samps_pois\n",
    "\n",
    "    def forecast_path(self, k, X = None, nsamps = 1):\n",
    "        X = self.make_pair(X)\n",
    "\n",
    "        samps_bern = self.bern_mod.forecast_path(k, X[0], nsamps)\n",
    "        samps_pois = self.pois_mod.forecast_path(k, X[1], nsamps) + np.ones([nsamps, k]) # Shifted Y values in the Poisson DGLM\n",
    "        return samps_bern * samps_pois\n",
    "\n",
    "    def forecast_path_copula(self, k, X = None, nsamps = 1, **kwargs):\n",
    "        X = self.make_pair(X)\n",
    "\n",
    "        samps_bern = self.bern_mod.forecast_path_copula(k, X[0], nsamps, **kwargs)\n",
    "        samps_pois = self.pois_mod.forecast_path_copula(k, X[1], nsamps, **kwargs) + np.ones([nsamps, k]) # Shifted Y values in the Poisson DGLM\n",
    "        return samps_bern * samps_pois\n",
    "\n",
    "    def forecast_path_lf_copula(self, k, X = None, phi_mu = None, phi_sigma = None, phi_psi = None, nsamps = 1, **kwargs):\n",
    "        X = self.make_pair(X)\n",
    "        if k == 2 and isinstance(phi_mu, (list, tuple)):\n",
    "            if not isinstance(phi_mu[0], (list, tuple)):\n",
    "                phi_mu = (phi_mu, phi_mu)\n",
    "                phi_sigma = (phi_sigma, phi_sigma)\n",
    "                phi_psi = (phi_psi, phi_psi)\n",
    "        else:\n",
    "            phi_mu = self.make_pair(phi_mu)\n",
    "            phi_sigma = self.make_pair(phi_sigma)\n",
    "            phi_psi = self.make_pair(phi_psi)\n",
    "\n",
    "        samps_bern = self.bern_mod.forecast_path_lf_copula(k, X[0], phi_mu = phi_mu[0], phi_sigma = phi_sigma[0], phi_psi = phi_psi[0], nsamps = nsamps, **kwargs)\n",
    "        samps_pois = self.pois_mod.forecast_path_lf_copula(k, X[1], phi_mu = phi_mu[1], phi_sigma = phi_sigma[1], phi_psi = phi_psi[1], nsamps = nsamps, **kwargs) + np.ones([nsamps, k]) # Shifted Y values in the Poisson DGLM\n",
    "        return samps_bern * samps_pois\n",
    "\n",
    "    def forecast_path_lf_copula_new(self, k, X = None, phi_mu = None, phi_sigma = None, phi_psi = None, nsamps = 1, **kwargs):\n",
    "        X = self.make_pair(X)\n",
    "        if k == 2 and isinstance(phi_mu, (list, tuple)):\n",
    "            if not isinstance(phi_mu[0], (list, tuple)):\n",
    "                phi_mu = (phi_mu, phi_mu)\n",
    "                phi_sigma = (phi_sigma, phi_sigma)\n",
    "                phi_psi = (phi_psi, phi_psi)\n",
    "        else:\n",
    "            phi_mu = self.make_pair(phi_mu)\n",
    "            phi_sigma = self.make_pair(phi_sigma)\n",
    "            phi_psi = self.make_pair(phi_psi)\n",
    "\n",
    "        return forecast_path_lf_dcmm(self, k, X[0], phi_mu[0], phi_sigma[0], phi_psi[0], nsamps=nsamps, **kwargs)\n",
    "\n",
    "\n",
    "    def forecast_path_lf_copula_density(self, y, k, X = None, phi_mu = None, phi_sigma = None, phi_psi = (None, None), nsamps = 1, **kwargs):\n",
    "        X = self.make_pair(X)\n",
    "        phi_mu = self.make_pair(phi_mu)\n",
    "        phi_sigma = self.make_pair(phi_sigma)\n",
    "        phi_psi = self.make_pair(phi_psi)\n",
    "\n",
    "        z = np.zeros([k])\n",
    "        y = y.reshape(-1)\n",
    "        z[y > 0] = 1\n",
    "        logdens_bern = self.bern_mod.forecast_path_lf_copula(k, X[0], phi_mu = phi_mu[0], phi_sigma = phi_sigma[0], phi_psi = phi_psi[0], nsamps = nsamps, y = z, **kwargs)\n",
    "        # Shifted Y values in the Poisson DGLM\n",
    "        y = y - 1\n",
    "        y = y.astype('float')\n",
    "        # 0's in the original data (now -1's) are considered 'missing by the Poisson model\n",
    "        y[y < 0] = np.nan\n",
    "        logdens_pois = self.pois_mod.forecast_path_lf_copula(k, X[1], phi_mu = phi_mu[1], phi_sigma = phi_sigma[1], phi_psi = phi_psi[1], nsamps = nsamps, y = y, **kwargs)\n",
    "        return logdens_bern, logdens_pois\n",
    "\n",
    "    def forecast_state_mean_and_var(self, k = 1, X = None):\n",
    "        mean_var_bern = self.bern_mod.forecast_state_mean_and_var(k, X[0])\n",
    "        mean_var_pois = self.pois_mod.forecast_state_mean_and_var(k, X[1])\n",
    "        return mean_var_bern, mean_var_pois\n",
    "\n",
    "    def make_pair(self, x):\n",
    "        if isinstance(x, (list, tuple)):\n",
    "            if len(x) == 2:\n",
    "                return x\n",
    "            else:\n",
    "                return (x, x)\n",
    "        else:\n",
    "            return (x, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A DCMM can be used in the same way as a DGLM, with the standard methods `dcmm.update`, `dcmm.forecast_marginal`, and `dcmm.forecast_path`. There are equivalent helper functions as well. A full analysis can be run with `analysis_dcmm`, and `define_dcmm` helps to initialize a DCMM. These helper functions assume that the same predictors `X` are used for the Bernoulli and Poisson DGLMs.\n",
    "\n",
    "The only difference from using a standard `dglm` is that outside of `analysis_dcmm`, the update and forecast functions do not automatically recognize whether the DCMM includes latent factors or call a copula for path forecasting. This means that the modeler needs to be more explicit in calling the correct method, such as `dcmm.forecast_path_copula` for path forecasting with a copula.\n",
    "\n",
    "A quick example of using `analysis_dcmm` to model simulated sales data follows. Another example with a DCMM can also be found [here](https://github.com/lavinei/pybats_nbdev/blob/master/examples/DCMM%20Latent%20Factor%20Example.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales</th>\n",
       "      <th>Price</th>\n",
       "      <th>Promotion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-06-01</th>\n",
       "      <td>15.0</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-06-02</th>\n",
       "      <td>13.0</td>\n",
       "      <td>2.19</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-06-03</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-06-04</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-06-05</th>\n",
       "      <td>6.0</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Sales  Price  Promotion\n",
       "Date                               \n",
       "2014-06-01   15.0   1.11        0.0\n",
       "2014-06-02   13.0   2.19        0.0\n",
       "2014-06-03    6.0   0.23        0.0\n",
       "2014-06-04    2.0  -0.05        1.0\n",
       "2014-06-05    6.0  -0.14        0.0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pybats.shared import load_sales_example2\n",
    "from pybats.analysis import analysis_dcmm\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "\n",
    "\n",
    "data = load_sales_example2()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_length = 25   # Number of days of data used to set prior\n",
    "k = 7               # Forecast horizon\n",
    "rho = 0.5           # Random effect discount factor to increase variance of forecast distribution\n",
    "forecast_samps = 1000  # Number of forecast samples to draw\n",
    "forecast_start = pd.to_datetime('2018-01-01') # Date to start forecasting\n",
    "forecast_end = pd.to_datetime('2018-05-01')   # Date to stop forecasting\n",
    "holidays = USFederalHolidayCalendar.rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beginning forecasting\n"
     ]
    }
   ],
   "source": [
    "mod, samples = analysis_dcmm(data['Sales'].values, data[['Price', 'Promotion']].values,\n",
    "                             k, forecast_start, forecast_end,\n",
    "                             nsamps=forecast_samps,\n",
    "                             prior_length=prior_length,\n",
    "                             seasPeriods=[7], seasHarmComponents=[[1,2,3]],\n",
    "                             dates=data.index, holidays=holidays,\n",
    "                             rho=rho,\n",
    "                             ret = ['model', 'forecast'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the DCMM is effectively a container for a Poisson and a Bernoulli DGLM, we can access each of them individually. The coefficients in the Bernoulli DGLM affect the probability of a non-zero observation, and the coefficients in the Poisson DGLM impact the size of any non-zero observations. To illustrate, we'll take a look at the holiday coefficients in both DGLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Holidays</th>\n",
       "      <th>Pois Mean</th>\n",
       "      <th>Pois Std Dev</th>\n",
       "      <th>Bern Mean</th>\n",
       "      <th>Bern Std Dev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Hol 1</th>\n",
       "      <td>New Years Day</td>\n",
       "      <td>-0.94</td>\n",
       "      <td>0.66</td>\n",
       "      <td>-0.78</td>\n",
       "      <td>1.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hol 2</th>\n",
       "      <td>Martin Luther King Jr. Day</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hol 3</th>\n",
       "      <td>Presidents Day</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hol 4</th>\n",
       "      <td>Memorial Day</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hol 5</th>\n",
       "      <td>July 4th</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hol 6</th>\n",
       "      <td>Labor Day</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hol 7</th>\n",
       "      <td>Columbus Day</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hol 8</th>\n",
       "      <td>Veterans Day</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hol 9</th>\n",
       "      <td>Thanksgiving</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hol 10</th>\n",
       "      <td>Christmas</td>\n",
       "      <td>-1.97</td>\n",
       "      <td>1.11</td>\n",
       "      <td>-1.10</td>\n",
       "      <td>1.23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Holidays  Pois Mean  Pois Std Dev  Bern Mean  \\\n",
       "Hol 1                New Years Day      -0.94          0.66      -0.78   \n",
       "Hol 2   Martin Luther King Jr. Day       0.20          0.43       0.08   \n",
       "Hol 3               Presidents Day      -0.27          0.46       0.27   \n",
       "Hol 4                 Memorial Day       0.62          0.40       0.04   \n",
       "Hol 5                     July 4th       1.10          0.43       0.04   \n",
       "Hol 6                    Labor Day       0.21          0.43       0.03   \n",
       "Hol 7                 Columbus Day      -0.04          0.45       0.21   \n",
       "Hol 8                 Veterans Day      -0.15          0.48       0.03   \n",
       "Hol 9                 Thanksgiving       0.14          0.43       0.16   \n",
       "Hol 10                   Christmas      -1.97          1.11      -1.10   \n",
       "\n",
       "        Bern Std Dev  \n",
       "Hol 1           1.29  \n",
       "Hol 2           1.41  \n",
       "Hol 3           1.39  \n",
       "Hol 4           1.41  \n",
       "Hol 5           1.41  \n",
       "Hol 6           1.41  \n",
       "Hol 7           1.39  \n",
       "Hol 8           1.41  \n",
       "Hol 9           1.39  \n",
       "Hol 10          1.23  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pois_hol = mod.pois_mod.get_coef('hol')\n",
    "bern_hol = mod.bern_mod.get_coef('hol')\n",
    "\n",
    "coef = pd.DataFrame({'Holidays':[h.name for h in holidays],\n",
    "                     'Pois Mean': pois_hol['Mean'],\n",
    "                     'Pois Std Dev': pois_hol['Standard Deviation'],\n",
    "                     'Bern Mean': bern_hol['Mean'],\n",
    "                     'Bern Std Dev': bern_hol['Standard Deviation']}).round(2)\n",
    "coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The largest negative coefficients are for Christmas and New Years Day, which means that they are more likely to have very low or $0$ sales.\n",
    "\n",
    "The largest positive coefficients are for July 4th and Memorial day, which means that they are likely to have increased sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_dglm.ipynb.\n",
      "Converted 01_update.ipynb.\n",
      "Converted 02_forecast.ipynb.\n",
      "Converted 03_define_models.ipynb.\n",
      "Converted 04_seasonal.ipynb.\n",
      "Converted 05_analysis.ipynb.\n",
      "Converted 06_conjugates.ipynb.\n",
      "Converted 07_point_forecast.ipynb.\n",
      "Converted 08_loss_functions.ipynb.\n",
      "Converted 09_plot.ipynb.\n",
      "Converted 10_shared.ipynb.\n",
      "Converted 11_dcmm.ipynb.\n",
      "Converted 12_dbcm.ipynb.\n",
      "Converted 13_latent_factor.ipynb.\n",
      "Converted 14_latent_factor_fxns.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
